mean((pred - carseats.test) ^ 2)
pruned.reg.tree <- prune.tree(reg.tree,best=11)
pred.pruned <- predict(pruned.reg.tree, newdata = Carseats[-train,])
mean((pred.pruned - carseats.test) ^ 2)
cv.reg.tree <- cv.tree(reg.tree)
best.tree <- which.min(cv.reg.tree$dev)
best.tree
cv.reg.tree <- cv.tree(reg.tree)
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree],col="red",cex=2.pch=20)
cv.reg.tree <- cv.tree(reg.tree)
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree],col="red",cex=2,pch=20)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree],col="red",cex=2,pch=20)
library(knitr)
#include_graphics("/Users/eli/Documents/Stanford/STAT\ 202/Homework/Homework4/Stat202_Homework4_Problem1.png")
library(tree)
library(ISLR)
train <- sample(1:nrow(Carseats), nrow(Carseats)/2)
reg.tree <- tree(Sales ~ ., Carseats, subset = train)
plot(reg.tree)
text(reg.tree,pretty=0)
pred <- predict(reg.tree, newdata = Carseats[-train,])
carseats.test <- Carseats[-train,"Sales"]
mean((pred - carseats.test) ^ 2)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree],col="red",cex=2,pch=20)
pruned.reg.tree <- prune.tree(reg.tree,best=11)
pred.pruned <- predict(pruned.reg.tree, newdata = Carseats[-train,])
mean((pred.pruned - carseats.test) ^ 2)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
set.seed(1)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
set.seed(1)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
set.seed(1)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
set.seed(1)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
library(knitr)
#include_graphics("/Users/eli/Documents/Stanford/STAT\ 202/Homework/Homework4/Stat202_Homework4_Problem1.png")
library(tree)
library(ISLR)
train <- sample(1:nrow(Carseats), nrow(Carseats)/2)
reg.tree <- tree(Sales ~ ., Carseats, subset = train)
plot(reg.tree)
text(reg.tree,pretty=0)
pred <- predict(reg.tree, newdata = Carseats[-train,])
carseats.test <- Carseats[-train,"Sales"]
mean((pred - carseats.test) ^ 2)
set.seed(1)
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
pruned.reg.tree <- prune.tree(reg.tree,best=11)
pred.pruned <- predict(pruned.reg.tree, newdata = Carseats[-train,])
mean((pred.pruned - carseats.test) ^ 2)
pruned.reg.tree <- prune.tree(reg.tree,best=best.tree)
pred.pruned <- predict(pruned.reg.tree, newdata = Carseats[-train,])
pruned.reg.tree <- prune.tree(reg.tree,best=8)
pred.pruned <- predict(pruned.reg.tree, newdata = Carseats[-train,])
mean((pred.pruned - carseats.test) ^ 2)
install.packages("randomForest")
library(tree)
library(ISLR)
library(randomForest)
library(tree)
library(ISLR)
library(randomForest)
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
bagging.carseats
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
test.bagging <- predict(bagging.carseats, carseats.test)
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
test.bagging <- predict(bagging.carseats, newdata= carseats.test)
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
test.bagging <- predict(bagging.carseats, newdata= Carseats[-train])
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
test.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
pred.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
pred.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
mse.bagging <- mean((pred.bagging - carseats.test)^2)
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
pred.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
mse.bagging <- mean((pred.bagging - carseats.test)^2)
mse.bagging
importance(bagging.carseats)
imp <- importance(bagging.carseats)
imp
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=3, importance= TRUE)
pred.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
mse.bagging <- mean((pred.bagging - carseats.test)^2)
mse.bagging
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=10, importance= TRUE)
pred.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
mse.bagging <- mean((pred.bagging - carseats.test)^2)
mse.bagging
imp <- importance(bagging.carseats)
imp
randForest <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
pred.randForest <- predict(randForest, newdata= Carseats[-train,])
mse.randForest <- mean((pred.randForest - carseats.test)^2)
mse.randForest
imp <- importance(randForest)
imp
randForest <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
pred.randForest <- predict(randForest, newdata= Carseats[-train,])
mse.randForest <- mean((pred.randForest - carseats.test)^2)
mse.randForest
imp <- importance(randForest)
imp
pruned.reg.tree <- prune.tree(reg.tree,best=8)
pred.pruned <- predict(pruned.reg.tree, newdata = Carseats[-train,])
paste("MSE:",mean((pred.pruned - carseats.test) ^ 2), sep=" ")
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=10, importance= TRUE)
pred.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
paste("MSE with cross-validation:", mse.bagging <- mean((pred.bagging - carseats.test)^2), sep=" ")
randForest <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
pred.randForest <- predict(randForest, newdata= Carseats[-train,])
paste("MSE for random forest:", mse.randForest <- mean((pred.randForest - carseats.test)^2), sep=" ")
?Hitters
library(ISLR)
?Hitters
library(tree)
library(randomForest)
Hitters
df = na.omit(Hitters, cols='Salary')
df
df = na.omit(Hitters, cols='Salary')
sum(is.na(df$Salary))
test <- df[-train]
View(test)
train
train <- df[1:200,:]
df[1,]
df[1:200,]
train
test
test
train
train <- df[1:4,]
train
train <- df[1:100,]
train
train <- df[1:200,]
train
test <- df[-train]
train <- df[1:200,]
test <- df[201:,]
train <- df[1:200,]
test <- df[201:nrow(df),]
train
test
df[1:3,]
train <- df[1:200,]
test <- df[201:nrow(df),]
library(gbm)
install.packages('gbm')
library(gbm)
library(gbm)
?gbm
?linspace
lambdas <- seq(0.001,0.2, by=0.01)
range(1,length(lambdas))
range(1, 10)
1:length(lambdas)
mse.list <- vector('list', length(lambdas))
for(i in 1:length(lambdas)){
boost <- gbm(Salary ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = lambdas[i] )
pred <- predict(boost, test, n.trees=1000)
mse.list[i] <- mean((pred - test$Salary)^2)
}
?plot
plot(lambdas, mse.list, xlab = "Shrinkage value", ylab = "MSE")
for(i in 1:length(lambdas)){
boost <- gbm(Salary ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = lambdas[i] )
pred <- predict(boost, test, n.trees=1000)
mse.list[i] <- mean((pred - train$Salary)^2)
}
plot(lambdas, mse.list, xlab = "Shrinkage value", ylab = "MSE")
for(i in 1:length(lambdas)){
boost <- gbm(Salary ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = lambdas[i] )
pred <- predict(boost, train, n.trees=1000)
mse.list[i] <- mean((pred - train$Salary)^2)
}
plot(lambdas, mse.list, xlab = "Shrinkage value", ylab = "MSE")
for(i in 1:length(lambdas)){
boost <- gbm(Salary ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = lambdas[i] )
pred.train <- predict(boost, train, n.trees=1000)
pred.test <- predict(boost, test, n.trees=1000)
mse.train[i] <- mean((pred.train - train$Salary)^2)
mse.test[i] <- mean((pred.test - test$Salary)^2)
}
mse.train <- vector('list', length(lambdas))
for(i in 1:length(lambdas)){
boost <- gbm(Salary ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = lambdas[i] )
pred.train <- predict(boost, train, n.trees=1000)
pred.test <- predict(boost, test, n.trees=1000)
mse.train[i] <- mean((pred.train - train$Salary)^2)
mse.test[i] <- mean((pred.test - test$Salary)^2)
}
mse.train <- vector('list', length(lambdas))
mse.test <- vector('list', length(lambdas))
for(i in 1:length(lambdas)){
boost <- gbm(Salary ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = lambdas[i] )
pred.train <- predict(boost, train, n.trees=1000)
pred.test <- predict(boost, test, n.trees=1000)
mse.train[i] <- mean((pred.train - train$Salary)^2)
mse.test[i] <- mean((pred.test - test$Salary)^2)
}
plot(lambdas, mse.list, xlab = "Shrinkage value", ylab = "MSE", main = "Train MSE for different shrinkage values")
plot(lambdas, mse.train, xlab = "Shrinkage value", ylab = "MSE", main = "Train MSE for different shrinkage values")
plot(lambdas, mse.test, xlab = "Shrinkage value", ylab = "MSE", main = "Test MSE for different shrinkage values")
?lm
lin.reg <- lm(Salary ~ ., data = train)
lin.pred <- predict(lin.reg, test)
library(glmnet)
install.packages("glmnet")
library(glmnet)
#predict Salary with Ridge Regression
grid <- 10^seq(10,-2,length=100)
ridge.reg <- glmnet(train, train$Salary, alpha=0, lambda=grid)
ridge.pred <- predict(rdige.reg, newx= test)
ridge.reg <- glmnet(train, train$Salary, alpha=0, lambda=grid)
#predict Salary with Ridge Regression
grid = 10^seq(10,-2,length=100)
ridge.reg <- glmnet(train, train$Salary, alpha=0, lambda=grid)
#predict Salary with Ridge Regression
grid  <- 10^seq(10,-2,length=100)
#predict Salary with Ridge Regression
X.train <- model.matrix(Salary~., train)[,-1]
X.test <- model.matrix(Salary~., test)[,-1]
ridge.reg <- glmnet(X, train$Salary, alpha=0, lambda=grid)
ridge.reg <- glmnet(X.train, train$Salary, alpha=0, lambda=grid)
ridge.pred <- predict(rdige.reg, newx= X.test)
ridge.mse <- mean((ridge.pred - test$Salary)^2)
ridge.pred <- predict(ridge.reg, newx= X.test)
ridge.mse <- mean((ridge.pred - test$Salary)^2)
paste("Linear Regression Test MSE:", lin.mse, sep = " ")
paste("Ridge Regression Test MSE:", ridge.mse, sep = " ")
paste("Gradient Boosting Test MSE:", min(mse.test), sep = " ")
paste("Linear Regression Test MSE:", lin.mse, sep = " ")
library(glmnet)
#predict Salary with Linear Regression
lin.reg <- lm(Salary ~ ., data = train)
lin.pred <- predict(lin.reg, test)
lin.mse <- mean((lin.pred - test$Salary))
#predict Salary with Ridge Regression
X.train <- model.matrix(Salary~., train)[,-1]
X.test <- model.matrix(Salary~., test)[,-1]
grid  <- 10^seq(10,-2,length=100)
ridge.reg <- glmnet(X.train, train$Salary, alpha=0, lambda=grid)
ridge.pred <- predict(ridge.reg, newx= X.test)
ridge.mse <- mean((ridge.pred - test$Salary)^2)
paste("Linear Regression Test MSE:", lin.mse, sep = " ")
paste("Ridge Regression Test MSE:", ridge.mse, sep = " ")
paste("Gradient Boosting Test MSE:", min(mse.test), sep = " ")
min(mse.test)
which.min(mse.test)
paste("Gradient Boosting Test MSE:", mse.test[which.min(mse.test)], sep = " ")
library(glmnet)
#predict Salary with Linear Regression
lin.reg <- lm(Salary ~ ., data = train)
lin.pred <- predict(lin.reg, test)
lin.mse <- mean((lin.pred - test$Salary))
#predict Salary with Ridge Regression
X.train <- model.matrix(Salary~., train)[,-1]
X.test <- model.matrix(Salary~., test)[,-1]
grid  <- 10^seq(10,-2,length=100)
ridge.reg <- glmnet(X.train, train$Salary, alpha=0, lambda=grid)
ridge.pred <- predict(ridge.reg, newx= X.test)
ridge.mse <- mean((ridge.pred - test$Salary)^2)
paste("Linear Regression Test MSE:", lin.mse, sep = " ")
paste("Ridge Regression Test MSE:", ridge.mse, sep = " ")
paste("Gradient Boosting Test MSE:", mse.test[which.min(mse.test)], sep = " ")
library(glmnet)
#predict Salary with Linear Regression
lin.reg <- lm(Salary ~ ., data = train)
lin.pred <- predict(lin.reg, test)
lin.mse <- mean((lin.pred - test$Salary)^2)
#predict Salary with Ridge Regression
X.train <- model.matrix(Salary~., train)[,-1]
X.test <- model.matrix(Salary~., test)[,-1]
grid  <- 10^seq(10,-2,length=100)
ridge.reg <- glmnet(X.train, train$Salary, alpha=0, lambda=grid)
ridge.pred <- predict(ridge.reg, newx= X.test)
ridge.mse <- mean((ridge.pred - test$Salary)^2)
paste("Linear Regression Test MSE:", lin.mse, sep = " ")
paste("Ridge Regression Test MSE:", ridge.mse, sep = " ")
paste("Gradient Boosting Test MSE:", mse.test[which.min(mse.test)], sep = " ")
summary(boost)
?Hitters
bagging <- randomForest(Salary ~., data = train, mtry=20, importance= TRUE)
bagging.pred <- predict(bagging, newdata= test)
mse.bagging <- mean((pred.bagging - carseats.test)^2)
paste("MSE for bagging:", mse.bagging , sep=" ")
bagging <- randomForest(Salary ~., data = train, mtry=19, importance= TRUE)
bagging.pred <- predict(bagging, newdata= test)
mse.bagging <- mean((pred.bagging - carseats.test)^2)
paste("MSE for bagging:", mse.bagging , sep=" ")
bagging <- randomForest(Salary ~., data = train, mtry=19, importance= TRUE)
bagging.pred <- predict(bagging, newdata= test)
mse.bagging <- mean((bagging.pred - test$Salary)^2)
paste("MSE for bagging:", mse.bagging , sep=" ")
df = na.omit(Hitters, cols='Salary')
sum(is.na(df$Salary))
library(knitr)
#include_graphics("/Users/eli/Documents/Stanford/STAT\ 202/Homework/Homework4/Stat202_Homework4_Problem1.png")
library(tree)
library(ISLR)
library(randomForest)
train <- sample(1:nrow(Carseats), nrow(Carseats)/2)
set.seed(1)
reg.tree <- tree(Sales ~ ., Carseats, subset = train)
plot(reg.tree)
text(reg.tree,pretty=0)
pred <- predict(reg.tree, newdata = Carseats[-train,])
carseats.test <- Carseats[-train,"Sales"]
paste("MSE:", mean((pred - carseats.test) ^ 2), sep=" ")
cv.reg.tree <- cv.tree(reg.tree)
plot(cv.reg.tree$size,cv.reg.tree$dev,type="b")
best.tree <- which.min(cv.reg.tree$dev)
points(best.tree,cv.reg.tree$dev[best.tree])
pruned.reg.tree <- prune.tree(reg.tree,best=8)
pred.pruned <- predict(pruned.reg.tree, newdata = Carseats[-train,])
paste("MSE for cross-validation:",mean((pred.pruned - carseats.test) ^ 2), sep=" ")
bagging.carseats <- randomForest(Sales ~., data = Carseats, subset = train, mtry=10, importance= TRUE)
pred.bagging <- predict(bagging.carseats, newdata= Carseats[-train,])
paste("MSE for bagging:", mse.bagging <- mean((pred.bagging - carseats.test)^2), sep=" ")
imp <- importance(bagging.carseats)
imp
randForest <- randomForest(Sales ~., data = Carseats, subset = train, mtry=6, importance= TRUE)
pred.randForest <- predict(randForest, newdata= Carseats[-train,])
paste("MSE for random forest:", mse.randForest <- mean((pred.randForest - carseats.test)^2), sep=" ")
imp <- importance(randForest)
imp
df = na.omit(Hitters, cols='Salary')
sum(is.na(df$Salary))
train <- df[1:200,]
test <- df[201:nrow(df),]
library(gbm)
set.seed(1)
lambdas <- seq(0.001,0.2, by=0.01)
mse.train <- vector('list', length(lambdas))
mse.test <- vector('list', length(lambdas))
for(i in 1:length(lambdas)){
boost <- gbm(Salary ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = lambdas[i] )
pred.train <- predict(boost, train, n.trees=1000)
pred.test <- predict(boost, test, n.trees=1000)
mse.train[i] <- mean((pred.train - train$Salary)^2)
mse.test[i] <- mean((pred.test - test$Salary)^2)
}
plot(lambdas, mse.train, xlab = "Shrinkage value", ylab = "MSE", main = "Train MSE for different shrinkage values")
plot(lambdas, mse.test, xlab = "Shrinkage value", ylab = "MSE", main = "Test MSE for different shrinkage values")
library(glmnet)
#predict Salary with Linear Regression
lin.reg <- lm(Salary ~ ., data = train)
lin.pred <- predict(lin.reg, test)
lin.mse <- mean((lin.pred - test$Salary)^2)
#predict Salary with Ridge Regression
X.train <- model.matrix(Salary~., train)[,-1]
X.test <- model.matrix(Salary~., test)[,-1]
grid  <- 10^seq(10,-2,length=100)
ridge.reg <- glmnet(X.train, train$Salary, alpha=0, lambda=grid)
ridge.pred <- predict(ridge.reg, newx= X.test)
ridge.mse <- mean((ridge.pred - test$Salary)^2)
paste("Linear Regression Test MSE:", lin.mse, sep = " ")
paste("Ridge Regression Test MSE:", ridge.mse, sep = " ")
paste("Gradient Boosting Test MSE:", mse.test[which.min(mse.test)], sep = " ")
summary(boost)
bagging <- randomForest(Salary ~., data = train, mtry=19, importance= TRUE)
bagging.pred <- predict(bagging, newdata= test)
mse.bagging <- mean((bagging.pred - test$Salary)^2)
paste("MSE for bagging:", mse.bagging , sep=" ")
df = na.omit(Hitters, cols='Salary')
sum(is.na(df$Salary))
?Caravan
train <- Caravan[1:1000,]
test <- Caravan[1001:nrows(Caravan)]
train <- Caravan[1:1000,]
test <- Caravan[1001:nrow(Caravan)]
test <- Caravan[1001:nrow(Caravan),]
boost <- gbm(Purchase ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = 0.01 )
summary(boost)
caravan.pred <- predict(booost, test, n.trees=1000)
caravan.pred <- predict(boost, test, n.trees=1000)
caravan.pred[1:15]
Caravan$Purchase
caravan.pred[1:100]
train$Purchase <- ifelse(Caravan$Purchase == "Yes",1,0)
train$Purchase <- ifelse(train$Purchase == "Yes",1,0)
test$Purchase <- ifelse(test$Purchase == "Yes",1,0)
boost <- gbm(Purchase ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = 0.01 )
boost <- gbm(Purchase ~ ., data = train, distribution = 'gaussian', n.trees = 1000, shrinkage = 0.01 )
summary(boost)
caravan.pred <- predict(boost, test, n.trees=1000)
caravan.pred[1:100]
caravan.pred <- predict(boost, test, n.trees=1000, type = "response")
caravan.pred[1:100]
predictions <- ifelse(caravan.pred >0.2,1,0)
table(test$Purchase, predictions)
conf <- table(test$Purchase, predictions)
conf[0]
conf[1]
conf[1][1]
conf[2]
conf[1][2]
conf[1[2]]
conf[1:2]
conf[1,1]
conf[1,2]
paste("Fraction of predicted purchasers who actually make a purchase: ", conf[2,2] / conf[1,2] + conf[2,2])
paste("Fraction of predicted purchasers who actually make a purchase: ", conf[2,2] / (conf[1,2] + conf[2,2]))
#comparison to linear regression
lin.caravan <- lm(Purchase ~., data = train)
lin.pred <- predict(lin.caravan, test)
#comparison to linear regression
lin.caravan <- lm(Purchase ~., data = train)
lin.pred <- predict(lin.caravan, test)
lin.pred <- ifelse(lin.pred > 0.2,1,0)
conf <- table(test$Purchase, lin.pred)
caravan.pred <- predict(boost, test, n.trees=1000, type = "response")
caravan.pred[1:100]
predictions <- ifelse(caravan.pred >0.2,1,0)
conf <- table(test$Purchase, predictions)
conf
paste("Fraction of predicted purchasers who actually make a purchase: ", conf[2,2] / (conf[1,2] + conf[2,2]))
caravan.pred <- predict(boost, test, n.trees=1000, type = "response")
caravan.pred[1:100]
predictions <- ifelse(caravan.pred >0.2,1,0)
conf <- table(test$Purchase, predictions)
conf
paste("Fraction of predicted purchasers who actually make a purchase: ", conf[2,2] / (conf[1,2] + conf[2,2]))
caravan.pred <- predict(boost, test, n.trees=1000, type = "response")
predictions <- ifelse(caravan.pred >0.2,1,0)
conf <- table(test$Purchase, predictions)
conf
paste("Fraction of predicted purchasers who actually make a purchase: ", conf[2,2] / (conf[1,2] + conf[2,2]))
caravan.pred <- predict(boost, test, n.trees=1000, type = "response")
predictions <- ifelse(caravan.pred >0.2,1,0)
conf <- table(test$Purchase, predictions)
conf
paste("Fraction of predicted purchasers who actually make a purchase in boosting model: ", conf[2,2] / (conf[1,2] + conf[2,2]))
#comparison to linear regression
lin.caravan <- lm(Purchase ~., data = train)
lin.pred <- predict(lin.caravan, test)
lin.pred <- ifelse(lin.pred > 0.2,1,0)
conf.lin <- table(test$Purchase, lin.pred)
conf.lin
paste("Fraction of predicted purchasers who actually make a purchase in linear model: ", conf.lin[2,2] / (conf.lin[1,2] + conf.lin[2,2]))
install.packages(c("Rcpp", "RcppParallel", "gmp"))
install.packages("http://www.louisaslett.com/HomomorphicEncryption/dl/HomomorphicEncryption_0.3.5.tgz", repos=NULL)
library(HomomorphicEncryption)
library(gmp)
library(Rcpp)
library(RcppParallel)
R.Version()
R.Version()
R.Version()
install.packages("libcurl4-openssl-dev")
install.packages("libcurl-devel")
library(HomomorphicEncryption)
install.packages("http://www.louisaslett.com/HomomorphicEncryption/dl/HomomorphicEncryption_0.3.5.tgz", repos=NULL)
library(HomomorphicEncryption)
library(HomomorphicEncryption)
install.packages("http://www.louisaslett.com/HomomorphicEncryption/dl/HomomorphicEncryption_0.3.5.tgz", repos=NULL)
library(HomomorphicEncryption)
install.packages("http://www.louisaslett.com/HomomorphicEncryption/dl/HomomorphicEncryption_0.3.5.tgz", repos=NULL)
library(HomomorphicEncryption)
install.packages("http://www.louisaslett.com/EncryptedStats/dl/EncryptedStats_0.5.tgz", repos=NULL)
library(EncryptedStats)
library(ggplot2)
library(dplyr)
setwd('/Users/eli/Documents/Spring 2021/CS8321/CS83212-Advanced-Neural-Networks/Final-Project/results')
