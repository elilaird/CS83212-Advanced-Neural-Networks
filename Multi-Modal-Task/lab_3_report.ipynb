{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Multi-modal and Multi-task\n",
    "\n",
    "**Group Members:**\n",
    "* Clay Harper\n",
    "* Eli Laird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report, we were to choose a dataset where a multi-modal model (multiple input streams), multi-task model (multiple predictive tasks), or both could be created.  We decided to use the 2018 OpenMic dataset because some of Clay's research is based in audio processing, and Eli has in interest in breaking into this field.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The 2018 OpenMic dataset [1] was created in a collaboration effort between Spotify and MARL@NYU (Music and Audio Research Laboratory New York University).\n",
    "\n",
    "### Classification Task\n",
    "\n",
    "The classification task is to determine what instruments are present in the audio clip.  Each audio clip may contain multiple instruments, so the task is to determine all instruments present in the clip.  The classification labels are:\n",
    "\n",
    "* accordion\n",
    "* banjo\n",
    "* bass\n",
    "* cello\n",
    "* clarinet\n",
    "* cymbals\n",
    "* drums\n",
    "* flute\n",
    "* guitar\n",
    "* mallet_percussion\n",
    "* mandolin\n",
    "* organ\n",
    "* piano\n",
    "* saxophone,\n",
    "* synthesizer\n",
    "* trombone\n",
    "* trumpet\n",
    "* ukulele\n",
    "* violin\n",
    "* voice\n",
    "\n",
    "Each audio clip has been labeled by a variety of people on which instruments are present in the clip.  Each person, depending on their area of expertise, is given a `worker_trust` score--so a piano player will get a high trust on identifying if there is a piano but maybe a lower trust in identifying a ukulele.  From that, a `relevance_score` is computed by a weighted sum of the `worker_trust` and the `label` (1 or 0) if the instrument was present.  Essentially, each audio clip is given a `relevance_score` for each instrument.  `relevance_score` is basically a confidence score for how likely this instrument appears in the audio clip.\n",
    "\n",
    "### Feature Data Format\n",
    "\n",
    "There are multiple options we can do for the feature data.  The data archive includes both raw audio files in the form of `.ogg` files and pre-computed VGGish Features [3].  If we wanted, we could featurize of the `.ogg` files by using the raw amplitude values, use MFCCs, CQT, etc.  For simplicity in this lab, we have decided to just use the VGGish features provided.   \n",
    "\n",
    "\n",
    "### Mulit-Modal/Multi-Task/Both?\n",
    "\n",
    "We thought about making this project be both multi-modal and multi-task, but since we are using the VGGish Features, we decided to just make this project muli-task where the tasks are identifying each instrument in the audio clip separately.\n",
    "\n",
    "### Who Collected the Data?\n",
    "\n",
    "Spotify and MARL@NYU (Music and Audio Research Laboratory New York University).  The cost of annotation was sponsored by Spotify.\n",
    "\n",
    "#### Why was the Data Collected?\n",
    "\n",
    "The idea was to create a dataset that can be used in music information retrieval through identifying different instruments in an audio clip.  Some applications of music information retrieval are music genre classification, recommender systems, music separation, automatic music transcription, music generation, and more [2]. To give an example of how this dataset could help Spotify, think of a user who wants to listen to piano music on a long day.  The user could go to the search bar on Spotify and type in piano.  In order to get good results, the Spotify must have piano tags associated with songs to return piano music.  This process of tagging can be very labor intensive and expensive because people have to listen to a song, identify it as piano music, and tag the song in the database.  This is increasingly difficult when more songs are constantly added to Spotify's database.  Instead, if we can create a model that is very good at listening to music and segmenting out the types of instruments in the music, we can help automate this process (also VGGish was developed by Google so...).  VGGish features are computed using a pre-trained CNN from Google based on [3], which essentially uses a very similar architecture to the VGG image classification architecture.  In total, there are 17 layers containing convolutional layers, activations, followed by maxpooling operations.  In the OpenMic version, VGGish Features are computed on an embedding layer in the VGGish archtitecture and then projected down to a _____ dimensional space using PCA. \n",
    "\n",
    "#### When was the Data Collected?\n",
    "\n",
    "The data was collected and put together in 2018.\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "We thought about discretizing the `relevance_score` by some threshold (say .5) and making this a binary classification problem for each instrument.  Instead, we decided to regress the `relevance_score` for each instrument because this allows for more post-processing, particularly in an example discussed above with a user searching for piano music.  If we used a threshold of .5, a `relevance_score` of .51 would mean that, yes, a piano appears in this audio clip.  Well, maybe the piano just appears for a breif amount of time in the audio clip and that's why it had a relatively low confidence score.  The user searching for piano music would likely want songs that are very piano-based--that's why they probably searched `piano`.  Regressing the relevance score instead would allow better post-processing where maybe we can sort the search results from highest to lowest `relevance_score` so the user is happier with the search results.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "[1] Humphrey, Eric J., Durand, Simon, and McFee, Brian. \"OpenMIC-2018: An Open Dataset for Multiple Instrument Recognition.\" in Proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR), 2018.\n",
    "\n",
    "[2] https://en.wikipedia.org/wiki/Music_information_retrieval#:~:text=Music%20information%20retrieval%20(MIR)%20is,with%20many%20real%2Dworld%20applications.\n",
    "\n",
    "[3] Shawn Hershey, Sourish Chaudhuri, Daniel P. W. Ellis, Jort F. Gemmeke, Aren Jansen, Channing Moore, Manoj Plakal, Devin Platt, Rif A. Saurous, Bryan Seybold, Malcolm Slaney, Ron Weiss, & Kevin Wilson (2017). CNN Architectures for Large-Scale Audio Classification. In International Conference on Acoustics, Speech and Signal Processing (ICASSP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many tasks or modalities are there in the dataset and how do you define each task or modality?\n",
    "\n",
    "There are 20 tasks (1 for each instrument), and there is 1 modality (the VGGish Feature).  \n",
    "\n",
    "****domains/cross domains\n",
    "\n",
    "**BEWARE**\n",
    "* TF2.0.0 isn't compatable with python > 3.7\n",
    "* Must use TF2.0.0 for maneframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TF Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../data'\n",
    "openmic_file_dir = os.path.join(datadir, 'openmic-2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data files are: ['X', 'Y_true', 'Y_mask', 'sample_key']\n",
      "Data shape: (20000, 10, 128)\n",
      "True label shape: (20000, 20)\n",
      "True label mask shape: (20000, 20)\n",
      "Total samples: (20000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accordion': 0,\n",
       " 'banjo': 1,\n",
       " 'bass': 2,\n",
       " 'cello': 3,\n",
       " 'clarinet': 4,\n",
       " 'cymbals': 5,\n",
       " 'drums': 6,\n",
       " 'flute': 7,\n",
       " 'guitar': 8,\n",
       " 'mallet_percussion': 9,\n",
       " 'mandolin': 10,\n",
       " 'organ': 11,\n",
       " 'piano': 12,\n",
       " 'saxophone': 13,\n",
       " 'synthesizer': 14,\n",
       " 'trombone': 15,\n",
       " 'trumpet': 16,\n",
       " 'ukulele': 17,\n",
       " 'violin': 18,\n",
       " 'voice': 19}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with np.load(os.path.join(openmic_file_dir, 'openmic-2018.npz'), allow_pickle=True) as data:\n",
    "    files = data.files\n",
    "    print(f'The data files are: {files}')\n",
    "    \n",
    "    x_total = data['X']\n",
    "    y = data['Y_true']\n",
    "#     y[y == .5] = 0 # weird dataset (.5 only occurs with their 50/50 shot--not ever a relevance score)\n",
    "    # Call it a soft-no since it appears in the individual df but not in the label df\n",
    "    y_mask = data['Y_mask']\n",
    "    sample_keys = data['sample_key']\n",
    "\n",
    "print(f'Data shape: {x_total.shape}')\n",
    "print(f'True label shape: {y.shape}')\n",
    "print(f'True label mask shape: {y_mask.shape}')\n",
    "print(f'Total samples: {sample_keys.shape}')\n",
    "\n",
    "with open(os.path.join(openmic_file_dir, 'class-map.json'), 'r') as f:\n",
    "    class_map = json.load(f)\n",
    "class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Into Train/Test\n",
    "\n",
    "**We can talk about this more later, could do 80/20 split-probably should do cross validation**\n",
    "\n",
    "**Using their split for now**\n",
    "\n",
    "**Well,...they have their own split.  Not sure if this is what Dr. Larson wants though**\n",
    "\n",
    "* Should be useful:\n",
    "    * https://github.com/cosmir/openmic-2018/blob/master/examples/modeling-baseline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_idexes = list(range(len(sample_keys)))\n",
    "k_folds = 5\n",
    "# Use for later when training datasets\n",
    "splitter = ShuffleSplit(n_splits=5, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 14915 test samples: 5085\n"
     ]
    }
   ],
   "source": [
    "# If we use their split\n",
    "split_train = pd.read_csv(os.path.join(openmic_file_dir, 'partitions/split01_train.csv'), \n",
    "                          header=None, squeeze=True)\n",
    "split_test = pd.read_csv(os.path.join(openmic_file_dir,'partitions/split01_test.csv'), \n",
    "                         header=None, squeeze=True)\n",
    "\n",
    "print(f'Train samples: {len(split_train)} test samples: {len(split_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000178_3840'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key_df = pd.DataFrame({'sample_key': sample_keys})\n",
    "sample_key_df['index'] = sample_key_df.index\n",
    "train_keys_df = pd.DataFrame({'sample_key': split_train})\n",
    "test_keys_df = pd.DataFrame({'sample_key': split_test})\n",
    "\n",
    "# Get the train and test indexes according to their split\n",
    "train_idxs = np.array(train_keys_df.merge(sample_key_df, on='sample_key', how='left')['index'])\n",
    "test_idxs = np.array(test_keys_df.merge(sample_key_df, on='sample_key', how='left')['index'])\n",
    "\n",
    "# Split the train/test data\n",
    "x_train, x_test = x_total[train_idxs], x_total[test_idxs]\n",
    "y_train, y_test = y[train_idxs], y[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14915, 10, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5085, 10, 128)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination Root File Already Exists\n",
      "CPU times: user 379 ms, sys: 117 ms, total: 496 ms\n",
      "Wall time: 673 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from librosa import load as load_audio\n",
    "from librosa.feature import mfcc as create_mfcc\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import glob, os, shutil\n",
    "\n",
    "# Create place to save mfcc\n",
    "src = os.path.join(openmic_file_dir, 'audio/')\n",
    "dest = os.path.join(openmic_file_dir, 'npy_audio/')\n",
    "\n",
    "def copy_tree(src, dest):\n",
    "    \n",
    "    def ig_f(dir, files):\n",
    "        return [f for f in files if os.path.isfile(os.path.join(dir, f))]\n",
    "    \n",
    "    if os.path.exists(dest):\n",
    "        print('Destination Root File Already Exists')\n",
    "    else:\n",
    "        shutil.copytree(src, dest, ignore=ig_f)\n",
    "        \n",
    "copy_tree(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(src + '**/*.ogg', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [37:28<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:29<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:31<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:32<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:34<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:34<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:35<00:00,  1.35s/it]\n",
      "100%|██████████| 1666/1666 [37:35<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:35<00:00,  1.35s/it]\n",
      "100%|██████████| 1666/1666 [37:37<00:00,  1.35s/it]\n",
      "100%|██████████| 1667/1667 [37:37<00:00,  1.35s/it]\n",
      "100%|██████████| 1666/1666 [37:37<00:00,  1.36s/it]\n",
      "100%|██████████| 12/12 [37:37<00:00, 188.15s/it]\n"
     ]
    }
   ],
   "source": [
    "def make_mfcc(file_chunk):\n",
    "    for file in tqdm(file_chunk, position=0, leave=True):\n",
    "        sr = 8000\n",
    "        audio, sr = load_audio(file, sr=sr)\n",
    "        clip_path = '/'.join(file.split('/')[-2:])\n",
    "        clip_path = dest + clip_path.split('.')[0] + '.npy'\n",
    "        np.save(clip_path, create_mfcc(audio, sr=sr, n_mfcc=20))\n",
    "    \n",
    "file_list = glob.glob(src + '**/*.ogg', recursive=True)\n",
    "\n",
    "max_workers = os.cpu_count()\n",
    "chunked_file_list = np.array_split(file_list, max_workers)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    _ = list(tqdm(executor.map(make_mfcc, chunked_file_list), total=len(chunked_file_list), \n",
    "                       position=0, leave=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_key</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000046_3840</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000046_3840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000135_483840</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000135_4838...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000139_119040</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000139_1190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000141_153600</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000141_1536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000144_30720</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000144_3072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14910</th>\n",
       "      <td>155294_184320</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155294_1843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14911</th>\n",
       "      <td>155295_76800</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155295_7680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14912</th>\n",
       "      <td>155307_211200</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155307_2112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913</th>\n",
       "      <td>155310_372480</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155310_3724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14914</th>\n",
       "      <td>155311_453120</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155311_4531...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14915 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sample_key                                               path\n",
       "0        000046_3840  ../data/openmic-2018/npy_audio/000/000046_3840...\n",
       "1      000135_483840  ../data/openmic-2018/npy_audio/000/000135_4838...\n",
       "2      000139_119040  ../data/openmic-2018/npy_audio/000/000139_1190...\n",
       "3      000141_153600  ../data/openmic-2018/npy_audio/000/000141_1536...\n",
       "4       000144_30720  ../data/openmic-2018/npy_audio/000/000144_3072...\n",
       "...              ...                                                ...\n",
       "14910  155294_184320  ../data/openmic-2018/npy_audio/155/155294_1843...\n",
       "14911   155295_76800  ../data/openmic-2018/npy_audio/155/155295_7680...\n",
       "14912  155307_211200  ../data/openmic-2018/npy_audio/155/155307_2112...\n",
       "14913  155310_372480  ../data/openmic-2018/npy_audio/155/155310_3724...\n",
       "14914  155311_453120  ../data/openmic-2018/npy_audio/155/155311_4531...\n",
       "\n",
       "[14915 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_npy_df = pd.DataFrame({'path': file_list})\n",
    "\n",
    "def get_sample_key(x):\n",
    "    base = x.split('/')[-1]\n",
    "    return base.split('.')[0]\n",
    "\n",
    "def fix_path(x):\n",
    "    clip_path = '/'.join(x.split('/')[-2:])\n",
    "    return dest + clip_path.split('.')[0] + '.npy'\n",
    "\n",
    "train_npy_df['sample_key'] = train_npy_df['path'].apply(get_sample_key)\n",
    "train_npy_df['path'] = train_npy_df['path'].apply(fix_path)\n",
    "train_npy_df = train_keys_df.merge(train_npy_df, on='sample_key', how='left')\n",
    "train_npy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_key</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000178_3840</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000178_3840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000308_61440</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000308_6144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000312_184320</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000312_1843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000319_145920</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000319_1459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000321_218880</td>\n",
       "      <td>../data/openmic-2018/npy_audio/000/000321_2188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>155175_38400</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155175_3840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>155176_23040</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155176_2304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>155178_0</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155178_0.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>155193_145920</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155193_1459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>155194_126720</td>\n",
       "      <td>../data/openmic-2018/npy_audio/155/155194_1267...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5085 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_key                                               path\n",
       "0       000178_3840  ../data/openmic-2018/npy_audio/000/000178_3840...\n",
       "1      000308_61440  ../data/openmic-2018/npy_audio/000/000308_6144...\n",
       "2     000312_184320  ../data/openmic-2018/npy_audio/000/000312_1843...\n",
       "3     000319_145920  ../data/openmic-2018/npy_audio/000/000319_1459...\n",
       "4     000321_218880  ../data/openmic-2018/npy_audio/000/000321_2188...\n",
       "...             ...                                                ...\n",
       "5080   155175_38400  ../data/openmic-2018/npy_audio/155/155175_3840...\n",
       "5081   155176_23040  ../data/openmic-2018/npy_audio/155/155176_2304...\n",
       "5082       155178_0    ../data/openmic-2018/npy_audio/155/155178_0.npy\n",
       "5083  155193_145920  ../data/openmic-2018/npy_audio/155/155193_1459...\n",
       "5084  155194_126720  ../data/openmic-2018/npy_audio/155/155194_1267...\n",
       "\n",
       "[5085 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_npy_df = pd.DataFrame({'path' : file_list})\n",
    "\n",
    "test_npy_df['sample_key'] = test_npy_df['path'].apply(get_sample_key)\n",
    "test_npy_df['path'] = test_npy_df['path'].apply(fix_path)\n",
    "test_npy_df = test_keys_df.merge(test_npy_df, on='sample_key', how='left')\n",
    "test_npy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14915/14915 [00:12<00:00, 1169.87it/s]\n"
     ]
    }
   ],
   "source": [
    "#train mfccs\n",
    "mfccs = []\n",
    "for file in tqdm(train_npy_df['path']):\n",
    "    mfccs.append(np.load(file, allow_pickle=True))\n",
    "    \n",
    "mfccs = np.hstack(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5085/5085 [00:03<00:00, 1274.01it/s]\n"
     ]
    }
   ],
   "source": [
    "#test mfss\n",
    "mfccs_test = []\n",
    "for file in tqdm(test_npy_df['path']):\n",
    "    mfccs_test.append(np.load(file, allow_pickle=True))\n",
    "    \n",
    "mfccs_test = np.hstack(mfccs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_mean = np.mean(mfccs, axis=1, keepdims=True)\n",
    "train_set_std = np.std(mfccs, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:32<00:00, 615.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Glorot initialize all mfccs \n",
    "npy_file_list = [fix_path(x) for x in file_list]\n",
    "\n",
    "for file in tqdm(npy_file_list):\n",
    "    mfccs = np.load(file, allow_pickle=True)\n",
    "    mfccs = (mfccs-train_set_mean)/train_set_std\n",
    "    np.save(file, mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glorot initialize all mfccs \n",
    "npy_file_list = [fix_path(x) for x in file_list]\n",
    "\n",
    "for file in tqdm(npy_file_list):\n",
    "    mfccs = np.load(file, allow_pickle=True)\n",
    "    mfccs = (mfccs-train_set_mean)/train_set_std\n",
    "    np.save(file, mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14915/14915 [00:10<00:00, 1403.33it/s]\n"
     ]
    }
   ],
   "source": [
    "mfccs_mean_std = []\n",
    "for file in tqdm(train_npy_df['path']):\n",
    "    mfccs_mean_std.append(np.load(file, allow_pickle=True))\n",
    "    \n",
    "mfccs_mean_std = np.array(mfccs_mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5085/5085 [00:01<00:00, 3659.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test_mfccs_mean_std = []\n",
    "for file in tqdm(test_npy_df['path']):\n",
    "    test_mfccs_mean_std.append(np.load(file, allow_pickle=True))\n",
    "    \n",
    "test_mfccs_mean_std = np.array(test_mfccs_mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14915, 20, 157)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_mean_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5085, 20, 157)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mfccs_mean_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insert architecture here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 10, 128)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 10, 128)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 20, 157)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling1d_1 (Gl (None, 128)          0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 1280)         0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 3140)         0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_variance_pooling1d_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 500)          640500      flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 500)          1570500     flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 500)          128500      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 250)          125250      dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 250)          125250      dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 250)          125250      dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 100)          25100       dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 100)          25100       dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 100)          25100       dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 300)          0           dense_29[0][0]                   \n",
      "                                                                 dense_32[0][0]                   \n",
      "                                                                 dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 20)           6020        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,796,570\n",
      "Trainable params: 2,796,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, Input, Layer, GlobalAveragePooling1D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "def create_nn():\n",
    "    inputs = Input(shape=(10, 128))\n",
    "    net = Flatten()(inputs)\n",
    "    net = Dense(500, activation='relu')(net)\n",
    "    net = Dense(250, activation='relu')(net)\n",
    "    net = Dense(100, activation='relu')(net)\n",
    "    #output = Dense(20, activation='linear')(net)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, net)\n",
    "    '''    adam = Adam(1e-4)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=['mse', 'mae'])'''\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class GlobalVariancePooling1D(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return K.var(x, axis=1)\n",
    "    \n",
    "    \n",
    "def create_nn_x_vec():\n",
    "    inputs = Input(shape=(10, 128))\n",
    "    gap = GlobalAveragePooling1D()(inputs)\n",
    "    gvp = GlobalVariancePooling1D()(inputs)\n",
    "    net = concatenate([gap, gvp])\n",
    "    net = Dense(500, activation='relu')(net)\n",
    "    net = Dense(250, activation='relu')(net)\n",
    "    net = Dense(100, activation='relu')(net)\n",
    "    #output = Dense(20, activation='linear')(net)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, net)\n",
    "    ''' adam = Adam(1e-4)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=['mse', 'mae'])'''\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_mfcc_nn():\n",
    "    inputs = Input(shape=(20, 157))\n",
    "    net = Flatten()(inputs)\n",
    "    net = Dense(500, activation='relu')(net)\n",
    "    net = Dense(250, activation='relu')(net)\n",
    "    net = Dense(100, activation='relu')(net)\n",
    "    \n",
    "    model = Model(inputs, net)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_multi_modal_nn():\n",
    "    m1 = create_nn()\n",
    "    m2 = create_mfcc_nn()\n",
    "    m3 = create_nn_x_vec()\n",
    "    \n",
    "    net = tf.keras.layers.Concatenate()([m1.output, m2.output, m3.output])\n",
    "    output = Dense(20, activation='relu')(net)\n",
    "    \n",
    "    model = Model(inputs=[m1.input, m2.input, m3.input], outputs=[output])\n",
    "    \n",
    "    adam = Adam(1e-4)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=['mse', 'mae']) \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "multi_modal_nn = create_multi_modal_nn()\n",
    "multi_modal_nn.summary()\n",
    "\n",
    "plot_model(multi_modal_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.data.Dataset import from_tensor_slices\n",
    "batch_size = 16\n",
    "\n",
    "# Convert to tf data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({'train_input_1':x_train,'train_input_2':mfccs_mean_std,'train_input_3':x_train}, y_train)).cache().shuffle(100).batch(batch_size).repeat()\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({'test_input_1':x_test,'test_input_2':test_mfccs_mean_std,'test_input_3':x_test}, y_test)).cache().shuffle(100).batch(batch_size).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ({train_input_1: (None, 10, 128), train_input_2: (None, 20, 157), train_input_3: (None, 10, 128)}, (None, 20)), types: ({train_input_1: tf.int64, train_input_2: tf.float32, train_input_3: tf.int64}, tf.float64)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 935 steps\n",
      "Epoch 1/1000\n",
      "  1/935 [..............................] - ETA: 8:03WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-82eee7c13c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;31m#validation_steps=val_steps_per_epoch,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m117\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"\"\"A single step of the distributed execution across replicas.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     x, y, sample_weights = _prepare_feed_values(\n\u001b[0;32m---> 66\u001b[0;31m         model, input_iterator, mode)\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Call `Model.{train,test,predict}_on_batch` on every replica passing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# PerReplicas as arguments.  On every replica inside this call, each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_prepare_feed_values\u001b[0;34m(model, inputs, mode)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;31m# correct order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;31m# correct order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_9'"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='./models/multi.h5'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=.1, patience=5, min_lr=1e-6),\n",
    "    EarlyStopping(patience=7)\n",
    "]\n",
    "\n",
    "train_steps_per_epoch = len(x_train)//batch_size + len(x_train)%batch_size\n",
    "val_steps_per_epoch = len(x_test)//batch_size + len(x_test)%batch_size\n",
    "multi_modal_nn.fit(train_dataset, validation_data=test_dataset,\n",
    "                    epochs=1000, callbacks=callbacks,\n",
    "                    steps_per_epoch=train_steps_per_epoch,\n",
    "                    validation_steps=val_steps_per_epoch,\n",
    "                    verbose=1)\n",
    "\n",
    "print('='*117)\n",
    "print('Results:')\n",
    "\n",
    "_, mse, mae = multi_modal_nn.evaluate(test_dataset, steps=val_steps_per_epoch, verbose=0)\n",
    "print(f'MSE: {mse:.2f}\\tMAE: {mae:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 935 steps, validate for 330 steps\n",
      "Epoch 1/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 14967.6204 - mse: 14980.5889 - mae: 54.5322 - val_loss: 44.7848 - val_mse: 44.8092 - val_mae: 2.0801\n",
      "Epoch 2/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 18.5767 - mse: 18.5926 - mae: 1.2146 - val_loss: 9.2180 - val_mse: 9.2231 - val_mae: 0.8276\n",
      "Epoch 3/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 3.8687 - mse: 3.8718 - mae: 0.6681 - val_loss: 4.6060 - val_mse: 4.6085 - val_mae: 0.6490\n",
      "Epoch 4/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 1.1773 - mse: 1.1781 - mae: 0.5503 - val_loss: 3.2636 - val_mse: 3.2653 - val_mae: 0.5901\n",
      "Epoch 5/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.5187 - mse: 0.5189 - mae: 0.5063 - val_loss: 2.6178 - val_mse: 2.6182 - val_mae: 0.5588\n",
      "Epoch 6/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.3055 - mse: 0.3056 - mae: 0.4811 - val_loss: 2.3047 - val_mse: 2.3059 - val_mae: 0.5365\n",
      "Epoch 7/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.2439 - mse: 0.2440 - mae: 0.4617 - val_loss: 2.2026 - val_mse: 2.2037 - val_mae: 0.5161\n",
      "Epoch 8/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.2129 - mse: 0.2129 - mae: 0.4395 - val_loss: 2.1133 - val_mse: 2.1144 - val_mae: 0.4902\n",
      "Epoch 9/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.1859 - mse: 0.1859 - mae: 0.4108 - val_loss: 2.0313 - val_mse: 2.0324 - val_mae: 0.4549\n",
      "Epoch 10/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.1548 - mse: 0.1549 - mae: 0.3734 - val_loss: 1.9830 - val_mse: 1.9841 - val_mae: 0.4133\n",
      "Epoch 11/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.1210 - mse: 0.1210 - mae: 0.3283 - val_loss: 1.9223 - val_mse: 1.9233 - val_mae: 0.3651\n",
      "Epoch 12/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0896 - mse: 0.0896 - mae: 0.2782 - val_loss: 1.8824 - val_mse: 1.8834 - val_mae: 0.3140\n",
      "Epoch 13/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0632 - mse: 0.0632 - mae: 0.2265 - val_loss: 1.8639 - val_mse: 1.8649 - val_mae: 0.2629\n",
      "Epoch 14/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1767 - val_loss: 1.8248 - val_mse: 1.8258 - val_mae: 0.2154\n",
      "Epoch 15/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0315 - mse: 0.0315 - mae: 0.1325 - val_loss: 1.8150 - val_mse: 1.8160 - val_mae: 0.1755\n",
      "Epoch 16/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0250 - mse: 0.0250 - mae: 0.0972 - val_loss: 1.8108 - val_mse: 1.8119 - val_mae: 0.1462\n",
      "Epoch 17/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0223 - mse: 0.0223 - mae: 0.0739 - val_loss: 1.8091 - val_mse: 1.8101 - val_mae: 0.1299\n",
      "Epoch 18/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0214 - mse: 0.0214 - mae: 0.0638 - val_loss: 1.8086 - val_mse: 1.8096 - val_mae: 0.1251\n",
      "Epoch 19/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0610 - val_loss: 1.8085 - val_mse: 1.8095 - val_mae: 0.1236\n",
      "Epoch 20/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0601 - val_loss: 1.8079 - val_mse: 1.8089 - val_mae: 0.1228\n",
      "Epoch 21/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0597 - val_loss: 1.8079 - val_mse: 1.8089 - val_mae: 0.1227\n",
      "Epoch 22/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0597 - val_loss: 1.8079 - val_mse: 1.8089 - val_mae: 0.1228\n",
      "Epoch 23/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0597 - val_loss: 1.8085 - val_mse: 1.8095 - val_mae: 0.1230\n",
      "Epoch 24/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0597 - val_loss: 1.8079 - val_mse: 1.8089 - val_mae: 0.1228\n",
      "Epoch 25/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0597 - val_loss: 1.8079 - val_mse: 1.8089 - val_mae: 0.1228\n",
      "Epoch 26/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0601 - val_loss: 1.8085 - val_mse: 1.8095 - val_mae: 0.1230\n",
      "Epoch 27/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0600 - val_loss: 1.8085 - val_mse: 1.8095 - val_mae: 0.1229\n",
      "Epoch 28/1000\n",
      "935/935 [==============================] - 2s 2ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.0599 - val_loss: 1.8085 - val_mse: 1.8095 - val_mae: 0.1229\n",
      "=====================================================================================================================\n",
      "Results:\n",
      "MSE: 1.81\tMAE: 0.123\n"
     ]
    }
   ],
   "source": [
    "model = create_nn_x_vec()\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='./models/x_vec_dense.h5'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=.1, patience=5, min_lr=1e-6),\n",
    "    EarlyStopping(patience=7)\n",
    "]\n",
    "\n",
    "train_steps_per_epoch = len(x_train)//batch_size + len(x_train)%batch_size\n",
    "val_steps_per_epoch = len(x_test)//batch_size + len(x_test)%batch_size\n",
    "model.fit(train_dataset, validation_data=test_dataset,\n",
    "                    epochs=1000, callbacks=callbacks,\n",
    "                    steps_per_epoch=train_steps_per_epoch,\n",
    "                    validation_steps=val_steps_per_epoch,\n",
    "                    verbose=1)\n",
    "\n",
    "print('='*117)\n",
    "print('Results:')\n",
    "\n",
    "_, mse, mae = model.evaluate(test_dataset, steps=val_steps_per_epoch, verbose=0)\n",
    "print(f'MSE: {mse:.2f}\\tMAE: {mae:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
