{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7938ef7",
   "metadata": {},
   "source": [
    "# Lab 3: Multi-modal and Multi-task\n",
    "\n",
    "**Group Members:**\n",
    "* Clay Harper\n",
    "* Eli Laird"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12175eba",
   "metadata": {},
   "source": [
    "In this report, we were to choose a dataset where a multi-modal model (multiple input streams), multi-task model (multiple predictive tasks), or both could be created.  We decided to use the 2018 OpenMic dataset because some of Clay's research is based in audio processing, and Eli has in interest in breaking into this field.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f006a9",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The 2018 OpenMic dataset [1] was created in a collaboration effort between Spotify and MARL@NYU (Music and Audio Research Laboratory New York University).\n",
    "\n",
    "### Classification Task\n",
    "\n",
    "\n",
    "\n",
    "### Feature Data Format\n",
    "\n",
    "### Mulit-Modal/Multi-Task/Both?\n",
    "\n",
    "### Who Collected the Data?\n",
    "\n",
    "#### Why was the Data Collected?\n",
    "\n",
    "The idea was to create a dataset that can be used in music information retrieval through identifying different instruments in an audio clip.  Some applications of music information retrieval are music genre classification, recommender systems, music separation, automatic music transcription, music generation, and more [2]. To give an example of how this dataset could help Spotify, think of a user who wants to listen to piano music on a long day.  The user could go to the search bar on Spotify and type in piano.  In order to get good results, the Spotify must have piano tags associated with songs to return piano music.  This process of tagging can be very labor intensive and expensive because people have to listen to a song, identify it as piano music, and tag the song in the database.  This is increasingly difficult when more songs are constantly added to Spotify's database.  Instead, if we can create a model that is very good at listening to music and segmenting out the types of instruments in the music, we can help automate this process. \n",
    "\n",
    "#### When was the Data Collected?\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "\n",
    "[1] Humphrey, Eric J., Durand, Simon, and McFee, Brian. \"OpenMIC-2018: An Open Dataset for Multiple Instrument Recognition.\" in Proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR), 2018.\n",
    "\n",
    "[2] https://en.wikipedia.org/wiki/Music_information_retrieval#:~:text=Music%20information%20retrieval%20(MIR)%20is,with%20many%20real%2Dworld%20applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ea12c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
