{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/elilaird/CS83212-Advanced-Neural-Networks/blob/main/Lab2_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jf5OYNnUIGrM"
   },
   "source": [
    "# Lab 2: Style Transfer\n",
    "\n",
    "**Group Members:**\n",
    "* Clay Harper\n",
    "* Eli Laird\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quM4QpEhKSp0",
    "outputId": "ac58c40b-204e-40f0-fcc7-37b345826914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.4.1\n",
      "Keras version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Keras version: {keras.__version__}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "#from tqdm import \n",
    "import copy\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, Model, Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Input, UpSampling2D, Conv2DTranspose, Layer\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.image import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaQOhCt5J23c"
   },
   "source": [
    "## VGG Manipulation\n",
    "\n",
    "Here, we need to manipulate the given VGG code (courtesy of Justin Ledford) to make use of pooling layers or strided convolutions alternatively.  We chose to use strided convolutions because it is less computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Le6MnUcMIAy2",
    "outputId": "85376331-57ea-49c2-92c8-8ef67f291e8f"
   },
   "outputs": [],
   "source": [
    "# Load VGG\n",
    "pre_trained_model = tf.keras.applications.VGG19(include_top=False,\n",
    "                                                      weights='imagenet')\n",
    "\n",
    "def vgg_layers(inputs, target_layer):\n",
    "#     with tf.device('/cpu:0'):\n",
    "#         # Block 1\n",
    "#         x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "#         if target_layer == 1:\n",
    "#             return x\n",
    "#         # Strides instead of maxpooling \n",
    "#         x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', strides=2)(x)\n",
    "#         # x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "#         # Block 2\n",
    "#         x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "#         if target_layer == 2:\n",
    "#             return x\n",
    "#         x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', strides=2)(x)\n",
    "#         # x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "#         # Block 3\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "#         if target_layer == 3:\n",
    "#             return x\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4', strides=2)(x)\n",
    "#         # x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "#         # Block 4\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "#         if target_layer == 4:\n",
    "#             return x\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4', strides=2)(x)\n",
    "#         # x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "#         # Block 5\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "#         return x\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    if target_layer == 1:\n",
    "        return x\n",
    "    # Strides instead of maxpooling \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', strides=2)(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    if target_layer == 2:\n",
    "        return x\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', strides=2)(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    if target_layer == 3:\n",
    "        return x\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4', strides=2)(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    if target_layer == 4:\n",
    "        return x\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4', strides=2)(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    return x\n",
    "\n",
    "def load_weights(trained_model, model):\n",
    "    layer_names = [layer.name for layer in trained_model.layers]\n",
    "\n",
    "    for layer in model.layers:\n",
    "        b_name = layer.name.encode()\n",
    "        if b_name in layer_names:\n",
    "            layer.set_weights(trained_model.get_layer(b_name).get_weights())\n",
    "            layer.trainable = False\n",
    "\n",
    "def VGG19(trained_model, input_tensor=None, input_shape=None, target_layer=1):\n",
    "    \"\"\"\n",
    "    VGG19, up to the target layer (1 for relu1_1, 2 for relu2_1, etc.)\n",
    "    \"\"\"\n",
    "    if input_tensor is None:\n",
    "        inputs = Input(shape=input_shape)\n",
    "    else:\n",
    "        inputs = Input(tensor=input_tensor, shape=input_shape)\n",
    "    model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    load_weights(trained_model, model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjDwH6xSTBMW"
   },
   "source": [
    "Create an encoder network from the pretrained VGG network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhDJoX1bIGcL",
    "outputId": "b4ae4fd1-e532-46bc-f35a-af270b6abc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "=================================================================\n",
      "Total params: 555,328\n",
      "Trainable params: 0\n",
      "Non-trainable params: 555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "target_layer = 3\n",
    "vgg_model = VGG19(pre_trained_model, input_shape=(256, 256, 3), target_layer=target_layer)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ur4iav2GTkyH"
   },
   "source": [
    "## Decoder Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6aMf8aNhTUsc"
   },
   "outputs": [],
   "source": [
    "def decoder_layers(inputs, layer):\n",
    "#     with tf.device('/cpu:0'): #******change to gpu later\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block5_conv1')(inputs)\n",
    "#         if layer == 5:\n",
    "#             return x\n",
    "\n",
    "\n",
    "#         #x = UpSampling2D((2, 2), name='decoder_block4_upsample')(x)\n",
    "#         x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block4_2DTrans')(x)\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv4')(x)\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv3')(x)\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv2')(x)\n",
    "#         x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv1')(x)\n",
    "#         if layer == 4:\n",
    "#             return x\n",
    "\n",
    "#         #x = UpSampling2D((2, 2), name='decoder_block3_upsample')(x)\n",
    "#         x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block3_2DTrans')(x)\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv4')(x)\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv3')(x)\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv2')(x)\n",
    "#         x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv1')(x)\n",
    "#         if layer == 3:\n",
    "#             return x\n",
    "\n",
    "#         #x = UpSampling2D((2, 2), name='decoder_block2_upsample')(x)\n",
    "#         x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block2_2DTrans')(x)\n",
    "#         x = Conv2D(128, (3, 3), activation='relu', padding='same', name='decoder_block2_conv2')(x)\n",
    "#         x = Conv2D(128, (3, 3), activation='relu', padding='same', name='decoder_block2_conv1')(x)\n",
    "#         if layer == 2:\n",
    "#             return x\n",
    "\n",
    "#         #x = UpSampling2D((2, 2), name='decoder_block1_upsample')(x)\n",
    "#         x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block1_2DTrans')(x)\n",
    "#         x = Conv2D(64, (3, 3), activation='relu', padding='same', name='decoder_block1_conv2')(x)\n",
    "#         x = Conv2D(64, (3, 3), activation='relu', padding='same', name='decoder_block1_conv1')(x)\n",
    "#         if layer == 1:\n",
    "#             return x\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block5_conv1')(inputs)\n",
    "    if layer == 5:\n",
    "        return x\n",
    "\n",
    "\n",
    "    #x = UpSampling2D((2, 2), name='decoder_block4_upsample')(x)\n",
    "    x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block4_2DTrans')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv4')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='decoder_block4_conv1')(x)\n",
    "    if layer == 4:\n",
    "        return x\n",
    "\n",
    "    #x = UpSampling2D((2, 2), name='decoder_block3_upsample')(x)\n",
    "    x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block3_2DTrans')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv4')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='decoder_block3_conv1')(x)\n",
    "    if layer == 3:\n",
    "        return x\n",
    "\n",
    "    #x = UpSampling2D((2, 2), name='decoder_block2_upsample')(x)\n",
    "    x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block2_2DTrans')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='decoder_block2_conv2')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='decoder_block2_conv1')(x)\n",
    "    if layer == 2:\n",
    "        return x\n",
    "\n",
    "    #x = UpSampling2D((2, 2), name='decoder_block1_upsample')(x)\n",
    "    x = Conv2DTranspose(1, kernel_size=(4,4), padding='same', strides=(2,2), name='decoder_block1_2DTrans')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='decoder_block1_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='decoder_block1_conv1')(x)\n",
    "    if layer == 1:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance Matching\n",
    "\n",
    "We decided to implement a covariance matching algorithm for the section where we got to choose one of the following:\n",
    "\n",
    "* smoothing constraint\n",
    "* style transfer with an image mask\n",
    "* different covariance matching algorithm\n",
    "* blend different styles in the reconstruction\n",
    "\n",
    "The implementation we are using was proposed in https://openaccess.thecvf.com/content_ICCV_2019/papers/Lu_A_Closed-Form_Solution_to_Universal_Style_Transfer_ICCV_2019_paper.pdf\n",
    "\n",
    "The closed form solution of the transformation matrix is:\n",
    "\n",
    "$$T = \\Sigma_c^{-1/2}(\\Sigma_c^{1/2}\\Sigma_s\\Sigma_c^{1/2})^{1/2}\\Sigma_c^{-1/2}$$\n",
    "\n",
    "Where taking a matrix to a power is defined as:\n",
    "\n",
    "$$A^\\alpha = \\Gamma\\Lambda^\\alpha\\Gamma^T$$\n",
    "\n",
    "Since the style image will always be the same in this architecture, we precompute the covariance of the style image and use it as a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sigma_s = np.cov(style_img)\n",
    "# img = tf.io.read_file('./../data/style.jpg')\n",
    "# img = tf.image.decode_image(img, channels=3).numpy()\n",
    "# # img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "# img ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_cov(self, x):\n",
    "#     with tf.device('/CPU:0'):\n",
    "#         x = x - tf.expand_dims(tf.reduce_mean(x, axis=1), 1)\n",
    "#         fact = tf.cast(tf.shape(x)[1] - 1, tf.float32)\n",
    "#         b = tf.cast(tf.math.conj(tf.transpose(x)), tf.float32)\n",
    "#         return tf.matmul(x, b) / fact\n",
    "\n",
    "    return tf.matmul(x, tf.transpose(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFTest(Layer):\n",
    "    def __init__(self, sigma_s, **kwargs):\n",
    "        super(TFTest, self).__init__()\n",
    "        self.sigma_s = sigma_s\n",
    "        \n",
    "    def matrix_to_power(self, matrix, power):\n",
    "        e_val, e_vec = tf.linalg.eigh(matrix)\n",
    "        lambda_ = tf.linalg.diag(e_val**power)\n",
    "\n",
    "        return e_vec@lambda_@tf.transpose(e_vec)\n",
    "    \n",
    "    def call(self, content_img):\n",
    "        # Reshape/squeeze to be the correct size \n",
    "        content_mat = tf.squeeze(content_img)\n",
    "        squeezed_shape = tf.shape(content_mat)\n",
    "        channels = tf.shape(content_mat)[-1]\n",
    "        content_mat = tf.reshape(content_mat, (channels, -1))\n",
    "        \n",
    "        sigma_c = tf.matmul(content_mat, tf.transpose(content_mat))\n",
    "        \n",
    "        sigma_c_neg_half = self.matrix_to_power(sigma_c, -1/2)\n",
    "        sigma_c_half = self.matrix_to_power(sigma_c, 1/2)\n",
    "        \n",
    "        inner_prod = tf.matmul(tf.matmul(sigma_c_half, self.sigma_s), sigma_c_half)\n",
    "        inner = self.matrix_to_power(inner_prod, 1/2)\n",
    "        \n",
    "        transform_mat = tf.matmul(tf.matmul(sigma_c_neg_half, inner), sigma_c_neg_half)\n",
    "        \n",
    "        transformed = tf.matmul(transform_mat, content_mat)\n",
    "        # add back batch dim and reshape\n",
    "        transformed = tf.reshape(transformed, content_mat)\n",
    "        return tf.expand_dims(transform_mat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma_s = np.cov(style_img)\n",
    "# img = tf.io.read_file('./../data/style.jpg')\n",
    "# img = tf.image.decode_image(img, channels=3)\n",
    "# img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "\n",
    "def matrix_to_power(matrix, power):\n",
    "    # Assuming real symmetric\n",
    "    e_val, e_vec = np.linalg.eigh(matrix)\n",
    "    lambda_ = np.diag(e_val**power)\n",
    "\n",
    "    return e_vec@lambda_@e_vec.T\n",
    "\n",
    "def new_transform(content_img, sigma_s):\n",
    "    print(type(content_img))\n",
    "    print(f'Received shape: {content_img.shape}')\n",
    "    \n",
    "    channel_dim = sigma_s.shape[0]\n",
    "    print(f'Channel dim: {channel_dim}')\n",
    "    \n",
    "    content_img = np.squeeze(content_img).reshape((channel_dim, -1))\n",
    "    print(f'content img shape: {content_img.shape}')\n",
    "    sigma_c = np.cov(content_img)\n",
    "    print(sigma_c.shape)\n",
    "    print(sigma_c)\n",
    "#     sigma_s = np.cov(style_img)\n",
    "\n",
    "\n",
    "    simga_c_neg_half = matrix_to_power(sigma_c, -1/2)\n",
    "    sigma_c_half = matrix_to_power(sigma_c, 1/2)\n",
    "\n",
    "    inner = matrix_to_power(sigma_c_half@sigma_s@sigma_c_half, 1/2)\n",
    "\n",
    "    transform_mat = simga_c_neg_half@inner@simga_c_neg_half\n",
    "    return transform_mat@content_img\n",
    "\n",
    "class CovarianceMatching(Layer):\n",
    "    def __init__(self, sigma_s, **kwargs):\n",
    "        super(CovarianceMatching, self).__init__()\n",
    "        self.sigma_s = sigma_s\n",
    "        \n",
    "    def call(self, xin):\n",
    "        xout = tf.py_function(new_transform, \n",
    "                           (xin, self.sigma_s),\n",
    "                           'float32',\n",
    "                           name='cov_matching')\n",
    "        xout = K.stop_gradient(xout) # explicitly set no grad\n",
    "        xout.set_shape(xin.shape) # explicitly set output shape\n",
    "        return xout\n",
    "    \n",
    "    def compute_output_shape(self, sin):\n",
    "        return sin.shape\n",
    "    \n",
    "\n",
    "class TFCovarianceMatching(Layer):\n",
    "    def __init__(self, sigma_s, **kwargs):\n",
    "        super(TFCovarianceMatching, self).__init__()\n",
    "        self.sigma_s = sigma_s\n",
    "        \n",
    "    #from https://stackoverflow.com/questions/47709854/how-to-get-covariance-matrix-in-tensorflow\n",
    "    def tf_cov(self, x):\n",
    "        with tf.device('/CPU:0'):\n",
    "            x = x - tf.expand_dims(tf.reduce_mean(x, axis=1), 1)\n",
    "            fact = tf.cast(tf.shape(x)[1] - 1, tf.float32)\n",
    "            b = tf.cast(tf.math.conj(tf.transpose(x)), tf.float32)\n",
    "            return tf.matmul(x, b) / fact\n",
    "\n",
    "\n",
    "    def matrix_to_power(self, matrix, power):\n",
    "        with tf.device('/CPU:0'):\n",
    "            # Assuming real symmetric\n",
    "            e_val, e_vec = tf.linalg.eigh(matrix)\n",
    "            lambda_ = tf.linalg.diag(e_val**power)\n",
    "\n",
    "            return e_vec@lambda_@tf.transpose(e_vec)\n",
    "\n",
    "    def call(self, content_img):\n",
    "        with tf.device('/CPU:0'):\n",
    "            h,w,c = content_img.shape[1:]\n",
    "            content_img = tf.squeeze(content_img)\n",
    "            content_img = tf.reshape(content_img, [h,w,c])\n",
    "            content_img = tf.reshape(content_img, [c, h * w]) \n",
    "\n",
    "            sigma_c = self.tf_cov(content_img)\n",
    "\n",
    "            sigma_c_neg_half = self.matrix_to_power(sigma_c, -1/2)\n",
    "            sigma_c_half = self.matrix_to_power(sigma_c, 1/2)\n",
    "            inner = self.matrix_to_power(sigma_c_half@self.sigma_s@sigma_c_half, 1/2)\n",
    "            transform_mat = sigma_c_neg_half@inner@sigma_c_neg_half\n",
    "\n",
    "            out = transform_mat@content_img\n",
    "            out = tf.reshape(out, [c,h,w])\n",
    "            out = tf.expand_dims(tf.reshape(out, [h,w,c]),0)\n",
    "\n",
    "            return out\n",
    "\n",
    "# tf.py_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96q2OyoLUqIq"
   },
   "source": [
    "## Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "J1zyMow9UmVL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "LAMBDA=1\n",
    "\n",
    "def l2_loss(x):\n",
    "    return K.sum(K.square(x)) / 2\n",
    "\n",
    "class EncoderDecoder:\n",
    "    def __init__(self, trained_model, input_shape=(256, 256, 3), target_layer=5, style_path='../data/style.jpg', decoder_path=None):\n",
    "        self.input_shape = input_shape\n",
    "        self.target_layer = target_layer\n",
    "        self.trained_model = trained_model\n",
    "\n",
    "    \n",
    "\n",
    "        self.encoder = VGG19(self.trained_model, input_shape=self.input_shape, target_layer=target_layer)\n",
    "        \n",
    "        # Load style image and add batch dim\n",
    "#         self.style_image = img_to_array(load_img(style_path, target_size=self.input_shape))\n",
    "        img = tf.io.read_file(style_path)\n",
    "        img = tf.image.decode_image(img, channels=3)\n",
    "        img = vgg_preprocess(img)\n",
    "        self.style_image = resize(img, self.encoder.input_shape[1:3])\n",
    "        style_latent = self.encoder(tf.expand_dims(self.style_image, axis=0)).numpy()\n",
    "        self.sigma_s = np.cov(np.squeeze(style_latent).reshape(style_latent.shape[-1], -1))\n",
    "        \n",
    "    \n",
    "        if decoder_path:\n",
    "            self.decoder = load_model(decoder_path)\n",
    "        else:\n",
    "            self.decoder = self.create_decoder(target_layer)\n",
    "            \n",
    "        # Create the complete model (encoder -> covar_match -> decoder)\n",
    "#         transformed_tensor = CovarianceMatching(self.sigma_s, name='covar_matching')(self.encoder.output)\n",
    "#         transformed_tensor = TFCovarianceMatching(self.sigma_s, name='covar_matching')(self.encoder.output)\n",
    "        \n",
    "        decoder_output = self.decoder(self.encoder.output)\n",
    "\n",
    "        self.model = Model(self.encoder.input, decoder_output)\n",
    "        \n",
    "        self.loss = self.create_loss_fn(self.encoder)\n",
    "\n",
    "        adam = Adam(learning_rate=1e-4)\n",
    "        self.model.compile(adam, self.loss)\n",
    "\n",
    "    def create_loss_fn(self, encoder):\n",
    "        def get_encodings(inputs):\n",
    "            encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n",
    "            return encoder.output\n",
    "\n",
    "        def loss(img_in, img_out):\n",
    "            encoding_in = get_encodings(img_in)\n",
    "            encoding_out = get_encodings(img_out)\n",
    "            return l2_loss(img_out - img_in) + \\\n",
    "                  LAMBDA*l2_loss(encoding_out - encoding_in)\n",
    "        return loss\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def create_decoder(self, target_layer):\n",
    "        inputs = Input(shape=self.encoder.output.shape[1:])\n",
    "        layers = decoder_layers(inputs, target_layer)\n",
    "        output = Conv2D(3, (3, 3), activation='relu', padding='same',\n",
    "                        name='decoder_out')(layers)\n",
    "        decoder = Model(inputs, output, name='decoder_%s' % target_layer)\n",
    "        print(decoder.summary())\n",
    "        return decoder\n",
    "    \n",
    "#     def create_transform_layer(self):\n",
    "#         inputs = Input(shape=self.encoder.output_shape[1:])\n",
    "#         output = new_transform(inputs, tf.constant(self.sigma_style, dtype=tf.float32))\n",
    "#         return Model(inputs, output)\n",
    "    \n",
    "#     def load_style_img(self, img_path):\n",
    "#         img = image.load_img(img_path)\n",
    "#         img = image.img_to_array(img)\n",
    "#         img = resize(img, (self.input_shape[0], self.input_shape[1]))\n",
    "#         #img = tf.reshape(img, [self.input_shape[2], self.input_shape[0], self.input_shape[1]])\n",
    "#         return tf.expand_dims(img, axis=0)\n",
    "    \n",
    "    def process_style_img(self, img):\n",
    "        out = self.encoder(img)  \n",
    "        out = tf.squeeze(out)\n",
    "        out = tf.reshape(out, [out.shape[2], out.shape[0] * out.shape[1]])\n",
    "#         return \n",
    "#         return tf_cov(out)\n",
    "    \n",
    "    def resize_for_transform(self,img):\n",
    "        img = tf.squeeze(img)\n",
    "\n",
    "        img = tf.reshape(img, [self.input_shape[2], self.input_shape[0], self.input_shape[1]])\n",
    "        return img\n",
    "    \n",
    "\n",
    "    def export_decoder(self):\n",
    "        self.decoder.save('decoder_%s.h5' % self.target_layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFOPUQs9WM89"
   },
   "source": [
    "## Train Two Decoders \n",
    "\n",
    "Decoders will be created based on the outputs of 2 different layers in the encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFCt6eYuVEWS",
    "outputId": "c8b7765e-f9c9-4585-a9ba-c678256aefca",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 64, 64, 256)]     0         \n",
      "_________________________________________________________________\n",
      "decoder_block5_conv1 (Conv2D (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "decoder_block4_2DTrans (Conv (None, 128, 128, 1)       8193      \n",
      "_________________________________________________________________\n",
      "decoder_block4_conv4 (Conv2D (None, 128, 128, 512)     5120      \n",
      "_________________________________________________________________\n",
      "decoder_block4_conv3 (Conv2D (None, 128, 128, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "decoder_block4_conv2 (Conv2D (None, 128, 128, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "decoder_block4_conv1 (Conv2D (None, 128, 128, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "decoder_block3_2DTrans (Conv (None, 256, 256, 1)       8193      \n",
      "_________________________________________________________________\n",
      "decoder_block3_conv4 (Conv2D (None, 256, 256, 256)     2560      \n",
      "_________________________________________________________________\n",
      "decoder_block3_conv3 (Conv2D (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "decoder_block3_conv2 (Conv2D (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "decoder_block3_conv1 (Conv2D (None, 256, 256, 256)     590080    \n",
      "_________________________________________________________________\n",
      "decoder_out (Conv2D)         (None, 256, 256, 3)       6915      \n",
      "=================================================================\n",
      "Total params: 10,060,805\n",
      "Trainable params: 10,060,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "decoder_3 (Functional)       (None, 256, 256, 3)       10060805  \n",
      "=================================================================\n",
      "Total params: 10,616,133\n",
      "Trainable params: 10,060,805\n",
      "Non-trainable params: 555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder = EncoderDecoder(pre_trained_model, target_layer=target_layer)\n",
    "encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0+nightly\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess\n",
    "print(f'{tfds.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.3 ms, sys: 2.01 ms, total: 47.3 ms\n",
      "Wall time: 46 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a dataset to train on (imagenette)\n",
    "data_loader = tfds.load(\"imagenette\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset shapes: {image: (None, None, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
       " 'validation': <PrefetchDataset shapes: {image: (None, None, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {image: (None, None, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, test_ds = data_loader['train'], data_loader['validation']\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train observations: 9469\n",
      "Test observations: 3925\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.image import resize\n",
    "train_ds, test_ds = data_loader['train'], data_loader['validation']\n",
    "\n",
    "# Add batches and preprocessing \n",
    "BATCH_SIZE=1\n",
    "n_train_observations = train_ds.cardinality().numpy()\n",
    "n_test_observations = test_ds.cardinality().numpy()\n",
    "\n",
    "steps_per_epoch = n_train_observations//BATCH_SIZE + n_train_observations%BATCH_SIZE\n",
    "validation_steps = n_test_observations//BATCH_SIZE + n_test_observations%BATCH_SIZE\n",
    "\n",
    "def preprocess(observation):\n",
    "    img = observation['image']\n",
    "    label = observation['label']\n",
    "    \n",
    "    # Resize to target shape\n",
    "    processed_img = resize(img, encoder_decoder.input_shape[:2])\n",
    "    \n",
    "    # vgg preprocess\n",
    "    processed_img = vgg_preprocess(processed_img)\n",
    "    \n",
    "#     return processed_img, label\n",
    "    return processed_img, processed_img #for encoder/decoder loss\n",
    "\n",
    "# train_ds = train_ds.map(\n",
    "#     lambda image, label: (preprocess(image), label)).shuffle(1000).batch(BATCH_SIZE).repeat()\n",
    "# test_ds = test_ds.map(\n",
    "#     lambda image, label: (preprocess(image), label)).shuffle(1000).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    lambda observation: preprocess(observation)).shuffle(1000).batch(BATCH_SIZE).repeat(1000)\n",
    "test_ds = test_ds.map(\n",
    "    lambda observation: preprocess(observation)).shuffle(1000).batch(BATCH_SIZE).repeat(1000)\n",
    "\n",
    "\n",
    "# train_ds = train_ds.batch(BATCH_SIZE).map(\n",
    "#     lambda image, label: (preprocess(image), label)).shuffle(1000).repeat()\n",
    "# test_ds = test_ds.batch(BATCH_SIZE).map(\n",
    "#     lambda image, label: (preprocess(image), label)).shuffle(1000).repeat()\n",
    "\n",
    "print(f'Train observations: {n_train_observations}')\n",
    "print(f'Test observations: {n_test_observations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 256, 256, 3), (None, 256, 256, 3)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# This needs to be in scope where model is defined\n",
    "# class OutputPreview(Callback):\n",
    "#     def __init__(self, model, test_img_path, increment, preview_dir_path):\n",
    "#         test_img = image.load_img(test_img_path)\n",
    "#         test_target = image.img_to_array(test_img)\n",
    "#         test_target = resize(test_target, (256,256)) #imresize(test_img, (256, 256, 3))\n",
    "#         #test_target = image.img_to_array(test_img)\n",
    "#         test_target = np.expand_dims(test_target, axis=0)\n",
    "#         self.test_img = test_target\n",
    "#         self.model = model\n",
    "\n",
    "#         self.preview_dir_path = preview_dir_path\n",
    "\n",
    "#         self.increment = increment\n",
    "#         self.iteration = 0\n",
    "\n",
    "#     def on_batch_end(self, batch, logs={}):\n",
    "#         if (self.iteration % self.increment == 0):\n",
    "#             output_img = self.model.predict(self.test_img)[0]\n",
    "#             fname = '%d.jpg' % self.iteration\n",
    "#             out_path = os.path.join(self.preview_dir_path, fname)\n",
    "#             imsave(out_path, output_img)\n",
    "\n",
    "#         self.iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-03e10288d18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "history = encoder_decoder.model.fit(train_ds,\n",
    "                                    epochs=1000,\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-c8ce9e5f439d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='./encoder_decoder.h5'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=.1, patience=5, min_lr=1e-6),\n",
    "    EarlyStopping(patience=7),\n",
    "#     OutputPreview(encoder_decoder, '../data/doge.jpg', 5000, './preview-%d' % target_layer)\n",
    "]\n",
    "\n",
    "history = encoder_decoder.model.fit(train_ds, validation_data=test_ds,\n",
    "                                    epochs=1000,\n",
    "                                    callbacks=callbacks,\n",
    "                                    steps_per_epoch=steps_per_epoch,\n",
    "                                    validation_steps=validation_steps,\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "covariance_matching (Covaria (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "decoder_3 (Functional)       (None, 256, 256, 3)       10060805  \n",
      "=================================================================\n",
      "Total params: 10,616,133\n",
      "Trainable params: 10,060,805\n",
      "Non-trainable params: 555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'imagenette',\n",
    "    split=['train', 'validation'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train observations: 9469\n",
      "Test observations: 3925\n",
      "3925\n"
     ]
    }
   ],
   "source": [
    "# Add batches and preprocessing \n",
    "BATCH_SIZE=1\n",
    "n_train_observations = ds_info.splits['train'].num_examples\n",
    "n_test_observations = ds_info.splits['validation'].num_examples\n",
    "\n",
    "steps_per_epoch = n_train_observations//BATCH_SIZE + n_train_observations%BATCH_SIZE\n",
    "validation_steps = n_test_observations//BATCH_SIZE + n_test_observations%BATCH_SIZE\n",
    "print(f'Train observations: {n_train_observations}')\n",
    "print(f'Test observations: {n_test_observations}')\n",
    "print(ds_info.splits['validation'].num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testing(img):\n",
    "    \n",
    "    # Resize to target shape\n",
    "    processed_img = resize(img, encoder_decoder.input_shape[:2])\n",
    "    \n",
    "    # vgg preprocess\n",
    "    processed_img = vgg_preprocess(processed_img)\n",
    "    \n",
    "    return processed_img\n",
    "\n",
    "ds_train = ds_train.map(lambda image, label: (testing(image), label))\n",
    "ds_train = ds_train.shuffle(n_train_observations)\n",
    "ds_train = ds_train.batch(1)\n",
    "# ds = ds.repeat()\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = ds_test.map(lambda image, label: (testing(image), label))\n",
    "ds_test = ds_test.shuffle(n_test_observations)\n",
    "ds_test = ds_test.batch(1)\n",
    "# ds = ds.repeat()\n",
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 256)\n",
      "<unknown>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-58-aa07504045c2>:19 call  *\n        content_mat = tf.reshape(content_mat, (channels, -1))\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:195 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py:8378 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:525 _apply_op_helper\n        raise err\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:515 _apply_op_helper\n        preferred_dtype=default_dtype)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py:265 constant\n        allow_broadcast=True)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (None, -1). Consider casting elements to a supported type.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-dd76fc40f7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# flattened = GlobalAveragePooling2D()(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-58-aa07504045c2>:19 call  *\n        content_mat = tf.reshape(content_mat, (channels, -1))\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:195 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py:8378 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:525 _apply_op_helper\n        raise err\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:515 _apply_op_helper\n        preferred_dtype=default_dtype)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py:265 constant\n        allow_broadcast=True)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (None, -1). Consider casting elements to a supported type.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "inputs = encoder_decoder.encoder.output\n",
    "# flattened = GlobalAveragePooling2D()(inputs)\n",
    "# covar = TFTest(sigma_s=tf.convert_to_tensor(np.cov(np.random.rand(256, 256)), dtype='float32'))(inputs)\n",
    "\n",
    "net = Dense(10)(covar)\n",
    "\n",
    "mod = Model(encoder_decoder.encoder.inputs, net)\n",
    "mod.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "=================================================================\n",
      "Total params: 555,328\n",
      "Trainable params: 0\n",
      "Non-trainable params: 555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mod = Model(encoder_decoder.encoder.input, encoder_decoder.decoder(encoder_decoder.encoder.output))\n",
    "mod = Model(encoder_decoder.encoder.input, encoder_decoder.encoder.output)\n",
    "mod.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=encoder_decoder.loss,\n",
    ")\n",
    "\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-60-581b4ad750c2>:54 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-60-581b4ad750c2>:50 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-2-6d8ba0bbdb9f>:97 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-2-6d8ba0bbdb9f>:44 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2685 _maybe_build\n        self.input_spec, inputs, self.name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer block1_conv1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-8e3cf09abe5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-60-581b4ad750c2>:54 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-60-581b4ad750c2>:50 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-2-6d8ba0bbdb9f>:97 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-2-6d8ba0bbdb9f>:44 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2685 _maybe_build\n        self.input_spec, inputs, self.name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer block1_conv1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "mod.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-60-581b4ad750c2>:54 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-60-581b4ad750c2>:50 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-2-6d8ba0bbdb9f>:97 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-2-6d8ba0bbdb9f>:44 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2685 _maybe_build\n        self.input_spec, inputs, self.name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer block1_conv1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-5802bd8ca6d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-60-581b4ad750c2>:54 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-60-581b4ad750c2>:50 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-2-6d8ba0bbdb9f>:97 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-2-6d8ba0bbdb9f>:44 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2685 _maybe_build\n        self.input_spec, inputs, self.name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer block1_conv1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder.model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 254, 254, 5)       140       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                60        \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Flatten(input_shape=(256, 256, 3)),\n",
    "#   tf.keras.layers.Dense(5,activation='relu'),\n",
    "#   tf.keras.layers.Dense(10)\n",
    "# ])\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "inputs = Input(shape=(256, 256, 3))\n",
    "net = Conv2D(5, (3,3))(inputs)\n",
    "net = tf.keras.layers.GlobalAveragePooling2D()(net)\n",
    "net = Dense(10)(net)\n",
    "\n",
    "model = Model(inputs, net)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "3678/9469 [==========>...................] - ETA: 30s - loss: 5.5712 - sparse_categorical_accuracy: 0.1741"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-39bfd7e03101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds, ds_info = tfds.load(\n",
    "    'imagenette',\n",
    "    split='train',\n",
    "    as_supervised=True,  # returns `(img, label)` instead of dict(image=, ...)\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testing(img):\n",
    "    \n",
    "    # Resize to target shape\n",
    "    processed_img = resize(img, encoder_decoder.input_shape[:2])\n",
    "    \n",
    "    # vgg preprocess\n",
    "    processed_img = vgg_preprocess(processed_img)\n",
    "    \n",
    "    return processed_img\n",
    "\n",
    "ds = ds.map(lambda image, label: (testing(image), label))\n",
    "ds = ds.shuffle(n_train_observations)\n",
    "ds = ds.batch(1)\n",
    "# ds = ds.repeat()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-147b34fd1ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-42-e8087fa9d216>:46 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-42-e8087fa9d216>:42 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-2-e2ef8083919b>:61 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-2-e2ef8083919b>:8 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2685 _maybe_build\n        self.input_spec, inputs, self.name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer block1_conv1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-6a650e76c103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-42-e8087fa9d216>:46 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-42-e8087fa9d216>:42 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-2-e2ef8083919b>:61 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-2-e2ef8083919b>:8 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2685 _maybe_build\n        self.input_spec, inputs, self.name)\n    /Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer block1_conv1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder.model.fit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'imagenette',\n",
    "    split=['train', 'validation'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(img, label):    \n",
    "    # Resize to target shape\n",
    "    processed_img = resize(img, encoder_decoder.input_shape[:2])\n",
    "    \n",
    "    # vgg preprocess\n",
    "    processed_img = vgg_preprocess(processed_img)\n",
    "    \n",
    "    return processed_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 196608)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               25165952  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 25,167,242\n",
      "Trainable params: 25,167,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "74/74 [==============================] - ETA: 0s - loss: 5935.3741 - sparse_categorical_accuracy: 0.2487"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When providing an infinite dataset, you must specify the number of steps to run (if you did not intend to create an infinite dataset, make sure to not call `repeat()` on the dataset).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-39bfd7e03101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1128\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1131\u001b[0m           val_logs = self.evaluate(\n\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, steps, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clayharper/anaconda/envs/ml_spring_21/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_validate_args\u001b[0;34m(self, y, sample_weights, steps)\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFINITE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         raise ValueError(\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;34m\"When providing an infinite dataset, you must specify \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m             \u001b[0;34m\"the number of steps to run (if you did not intend to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;34m\"create an infinite dataset, make sure to not call \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When providing an infinite dataset, you must specify the number of steps to run (if you did not intend to create an infinite dataset, make sure to not call `repeat()` on the dataset)."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 256, 256, 3), dtype=float32, numpy=\n",
      "array([[[[115.228966  , 122.38897   ,  42.48797   ],\n",
      "         [106.4399    , 113.59991   ,  34.542656  ],\n",
      "         [102.21725   , 108.49053   ,  31.843437  ],\n",
      "         ...,\n",
      "         [122.428185  , 119.80694   ,  85.49969   ],\n",
      "         [104.95162   , 100.83819   ,  66.93719   ],\n",
      "         [113.041466  , 107.45147   ,  73.55047   ]],\n",
      "\n",
      "        [[105.76412   , 112.549126  ,  32.648125  ],\n",
      "         [104.053185  , 110.52178   ,  31.780937  ],\n",
      "         [105.04928   , 110.580376  ,  35.491875  ],\n",
      "         ...,\n",
      "         [118.60787   , 116.95928   ,  82.429375  ],\n",
      "         [105.20553   , 102.49053   ,  68.21453   ],\n",
      "         [109.135216  , 106.42022   ,  72.14422   ]],\n",
      "\n",
      "        [[109.416466  , 115.40069   ,  35.85125   ],\n",
      "         [112.74459   , 117.96319   ,  40.999687  ],\n",
      "         [123.07662   , 127.611626  ,  54.02703   ],\n",
      "         ...,\n",
      "         [110.853966  , 111.56866   ,  76.667656  ],\n",
      "         [102.666466  , 103.07647   ,  68.17547   ],\n",
      "         [110.209435  , 110.61944   ,  75.71844   ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-14.505409  , -27.345406  , -46.246407  ],\n",
      "         [-16.790565  , -29.630562  , -48.531563  ],\n",
      "         [-16.548378  , -29.388374  , -48.289375  ],\n",
      "         ...,\n",
      "         [136.36569   , 118.455376  , 116.37078   ],\n",
      "         [ 71.61959   ,  51.467094  ,  52.034843  ],\n",
      "         [ 24.61959   ,   2.7795944 ,   5.8785934 ]],\n",
      "\n",
      "        [[ -6.9272842 , -19.76728   , -38.66828   ],\n",
      "         [ -4.7788467 , -17.618843  , -36.519844  ],\n",
      "         [ -0.90384674, -13.743843  , -32.644844  ],\n",
      "         ...,\n",
      "         [131.40475   , 113.49444   , 111.40984   ],\n",
      "         [ 58.49459   ,  37.81475   ,  38.3825    ],\n",
      "         [ 14.639122  ,  -7.2008743 ,  -4.1018753 ]],\n",
      "\n",
      "        [[  4.9750595 ,  -7.864937  , -26.765938  ],\n",
      "         [  2.326622  , -10.513374  , -29.414375  ],\n",
      "         [  5.920372  ,  -6.9196243 , -25.820625  ],\n",
      "         ...,\n",
      "         [119.27584   , 100.54131   ,  98.60906   ],\n",
      "         [ 37.79928   ,  16.803032  ,  17.37078   ],\n",
      "         [ -4.7749405 , -26.614937  , -23.515938  ]]]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([3])>)\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "for element in train_ds.take(2):\n",
    "    print(element)\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "Pp2COm9zVIml",
    "outputId": "da93c3c8-c68a-4d09-97fd-c0c06c9d4ab9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Eli's Disk/datasets/imagenette2/train\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "model_26 (Functional)        (1, 64, 64, 256)          0         \n",
      "_________________________________________________________________\n",
      "decoder_3 (Functional)       (None, 256, 256, 3)       10060805  \n",
      "=================================================================\n",
      "Total params: 10,616,133\n",
      "Trainable params: 10,060,805\n",
      "Non-trainable params: 555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import Callback\n",
    "#from scipy.misc import imresize, imsave DEPRACATED\n",
    "#from cv2 import resize\n",
    "from tensorflow.image import resize\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "#from model import EncoderDecoder\n",
    "#from util import count_num_samples\n",
    "\n",
    "DATASET_DIR = '/Volumes/Eli\\'s Disk/datasets'\n",
    "TRAIN_PATH = os.path.join(DATASET_DIR, 'imagenette2', 'train')\n",
    "VAL_PATH = os.path.join(DATASET_DIR, 'imagenette2', 'val')\n",
    "TARGET_SIZE = (256, 256)\n",
    "BATCH_SIZE = 1\n",
    "epochs = 2\n",
    "\n",
    "print(TRAIN_PATH)\n",
    "datagen = ImageDataGenerator()\n",
    "'''train_gen = datagen.flow_from_directory(TRAIN_PATH, target_size=TARGET_SIZE,\n",
    "                                  batch_size=BATCH_SIZE, class_mode=None)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(VAL_PATH, target_size=TARGET_SIZE,\n",
    "                                  batch_size=BATCH_SIZE, class_mode=None)'''\n",
    "\n",
    "(train,val), info = tfds.load(name='imagenette', \n",
    "                       batch_size=BATCH_SIZE, \n",
    "                       split=['train','validation'], \n",
    "                       with_info=True,\n",
    "                       download=True)\n",
    "\n",
    "\n",
    "def create_gen(ds):\n",
    "    def tuple_gen():\n",
    "        for i in ds:\n",
    "\n",
    "            # (X, y)\n",
    "            \n",
    "            img = tf.keras.applications.vgg19.preprocess_input(i['image'])\n",
    "            img = tf.image.resize(img, TARGET_SIZE)\n",
    "            yield (img,img)\n",
    "\n",
    "    return tuple_gen()\n",
    "\n",
    "train_gen = create_gen(train)\n",
    "val_gen = create_gen(val)\n",
    "'''train_gen = create_gen(TRAIN_PATH, TARGET_SIZE, BATCH_SIZE)\n",
    "val_gen = create_gen(VAL_PATH, TARGET_SIZE, BATCH_SIZE)'''\n",
    "\n",
    "# This needs to be in scope where model is defined\n",
    "class OutputPreview(Callback):\n",
    "    def __init__(self, model, test_img_path, increment, preview_dir_path):\n",
    "        test_img = image.load_img(test_img_path)\n",
    "        test_target = image.img_to_array(test_img)\n",
    "        test_target = resize(test_target, (256,256)) #imresize(test_img, (256, 256, 3))\n",
    "        #test_target = image.img_to_array(test_img)\n",
    "        test_target = np.expand_dims(test_target, axis=0)\n",
    "        self.test_img = test_target\n",
    "        self.model = model\n",
    "\n",
    "        self.preview_dir_path = preview_dir_path\n",
    "\n",
    "        self.increment = increment\n",
    "        self.iteration = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if (self.iteration % self.increment == 0):\n",
    "            output_img = self.model.predict(self.test_img)[0]\n",
    "            fname = '%d.jpg' % self.iteration\n",
    "            out_path = os.path.join(self.preview_dir_path, fname)\n",
    "            imsave(out_path, output_img)\n",
    "\n",
    "        self.iteration += 1\n",
    "\n",
    "\n",
    "num_samples = 9469 #count_num_samples(TRAIN_PATH)\n",
    "steps_per_epoch = num_samples // BATCH_SIZE\n",
    "\n",
    "target_layer = 3 #int(sys.argv[1])\n",
    "\n",
    "encoder_decoder = EncoderDecoder(trained_model=pre_trained_model, target_layer=target_layer)\n",
    "encoder_decoder.summary()\n",
    "\n",
    "callbacks = [OutputPreview(encoder_decoder, '../data/doge.jpg', 5000, './preview-%d' % target_layer)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "I0QDOgptL6jG",
    "outputId": "2752fb7e-7108-4fe8-819c-da5b5480dad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-10-e471bb66f049>:40 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-10-e471bb66f049>:36 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-51-e2ef8083919b>:61 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-51-e2ef8083919b>:8 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:188 build\n        input_channel = self._get_input_channel(input_shape)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:360 _get_input_channel\n        raise ValueError('The channel dimension of the inputs '\n\n    ValueError: The channel dimension of the inputs should be defined. Found `None`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-328284d77a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder_decoder.model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n\u001b[0;32m----> 2\u001b[0;31m         epochs=epochs, callbacks=callbacks, validation_data=val_gen)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-10-e471bb66f049>:40 loss  *\n        encoding_in = get_encodings(img_in)\n    <ipython-input-10-e471bb66f049>:36 get_encodings  *\n        encoder = VGG19(self.trained_model, inputs, self.input_shape, self.target_layer)\n    <ipython-input-51-e2ef8083919b>:61 VGG19  *\n        model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19', trainable=False)\n    <ipython-input-51-e2ef8083919b>:8 vgg_layers  *\n        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__  **\n        input_list)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:862 _infer_output_signature\n        self._maybe_build(inputs)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:188 build\n        input_channel = self._get_input_channel(input_shape)\n    /Users/eli/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py:360 _get_input_channel\n        raise ValueError('The channel dimension of the inputs '\n\n    ValueError: The channel dimension of the inputs should be defined. Found `None`.\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder.model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs, callbacks=callbacks, validation_data=val_gen)\n",
    "encoder_decoder.export_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXVOqTU7kbsl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jarB6zyyjr1Q"
   },
   "source": [
    "# Covariance matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7vdqwrnlR_B"
   },
   "source": [
    "## Dr. Larson \n",
    "\n",
    "Reusing code to test if mine works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "bSM1DMULjtSR",
    "outputId": "29516c6e-162a-4d35-b178-b7b6278403d3"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "channels = 5 # number of channels to simulate\n",
    "hw = 256 # height and width dimensions\n",
    "\n",
    "# Create some Activation tensors\n",
    "A1 = np.random.randn(channels,hw,hw)\n",
    "A2 = np.random.rand(channels,hw,hw)\n",
    "\n",
    "# make A1 low frequency  \n",
    "filt = np.ones((3,6,6))\n",
    "filt = filt / np.sum(filt)\n",
    "A1 = convolve(A1,filt)\n",
    "A1 = A1 - np.mean(A1)\n",
    "\n",
    "# make A2 high frequency\n",
    "filt = np.ones((2,3,3))\n",
    "filt = filt / np.sum(filt)\n",
    "filt[:,:,0] = filt[:,:,0]*(-1)\n",
    "filt[:,:,1] = 0\n",
    "A2 = convolve(A2,filt)\n",
    "A2 = A2 - np.mean(A2)\n",
    "\n",
    "# plot each tensor, average along channel\n",
    "def show_active(A,title=''):\n",
    "    plt.imshow(np.mean(A,0))\n",
    "    plt.title(title)\n",
    "\n",
    "n_plots = min(channels,10)\n",
    "plt.figure(figsize=(15,5))   \n",
    "for i in range(n_plots):\n",
    "    plt.subplot(1,n_plots,i+1)\n",
    "    plt.imshow(A1[i,:,:])\n",
    "    plt.title(f'A1 at {i}')\n",
    "    \n",
    "n_plots = min(channels,10)\n",
    "plt.figure(figsize=(15,5))   \n",
    "for i in range(n_plots):\n",
    "    plt.subplot(1,n_plots,i+1)\n",
    "    plt.imshow(A2[i,:,:])\n",
    "    plt.title(f'A2 at {i}')\n",
    "    \n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "show_active(A1,'A1 Mean over channels')\n",
    "plt.subplot(1,2,2)\n",
    "show_active(A2,'A2 Mean over channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "w9VvsCBKlWYO",
    "outputId": "415a1c24-a7c5-47d1-f12e-3588c849b31f"
   },
   "outputs": [],
   "source": [
    "# calculate gram matrix (vectorized spatially) and show it\n",
    "# for each activations\n",
    "def gram(x):\n",
    "    tmp = x.reshape((channels,hw*hw))\n",
    "    return tmp @ tmp.T / (channels*hw*hw)\n",
    "\n",
    "def show_gram(A,title=''):\n",
    "    plt.figure()\n",
    "    G = gram(A)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(G)\n",
    "    plt.title('Gram of '+title)\n",
    "    plt.subplot(1,2,1)\n",
    "    show_active(A,title)\n",
    "    return G\n",
    "    \n",
    "\n",
    "G_A1 = show_gram(A1,'A1')\n",
    "G_A2 = show_gram(A2,'A2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZwKUaS3IlZIa",
    "outputId": "2e9f6869-3d64-4a9f-c6cd-24db0477a581"
   },
   "outputs": [],
   "source": [
    "def whiten_cov(A):\n",
    "    Avec = A.reshape((channels,hw*hw))\n",
    "    AA = Avec @ Avec.T\n",
    "    # notice that the SVD is of the covariance matrix\n",
    "    u,s,vt = np.linalg.svd(AA,full_matrices=False)\n",
    "    \n",
    "    A_white = ((u @ np.diag(s**(-0.5)) @ vt) @ Avec) # no usage of the singular values here\n",
    "    return A_white, (u, s, vt), Avec\n",
    "    \n",
    "\n",
    "A1_white, A1SVDcov, A1vec = whiten_cov(A1)\n",
    "A2_white, A2SVDcov, A2vec = whiten_cov(A2)\n",
    "    \n",
    "u1, s1, _ = A1SVDcov\n",
    "u2, s2, _ = A2SVDcov\n",
    "\n",
    "# -------A1-------\n",
    "# Apply inverse reconstruction to get colored version\n",
    "A1_mixed_color = u2 @ np.diag(s2**(0.5)) @ u2.T @ A1_white\n",
    "A1_mixed_color = A1_mixed_color.reshape((channels,hw,hw))\n",
    "\n",
    "# -------A2-------\n",
    "# Apply inverse reconstruction to get colored version\n",
    "A2_mixed_color = u1 @ np.diag(s1**(0.5)) @ u1.T @ A2_white\n",
    "A2_mixed_color = A2_mixed_color.reshape((channels,hw,hw))\n",
    "\n",
    "diffA1 = np.mean((A1_mixed_color-A1)**2)\n",
    "diffA2 = np.mean((A2_mixed_color-A2)**2)\n",
    "\n",
    "# show originals\n",
    "# and colored versions\n",
    "G_A1 = show_gram(A1,'A1')\n",
    "_ = show_gram(A1_white.reshape((channels,hw,hw)),'A1_white')\n",
    "G_A1asA2 = show_gram(A1_mixed_color,'A1_mixed_color')\n",
    "\n",
    "# show originals\n",
    "# and colored versions\n",
    "G_A1 = show_gram(A2,'A2')\n",
    "_ = show_gram(A2_white.reshape((channels,hw,hw)),'A2_white')\n",
    "G_A2asA1 = show_gram(A2_mixed_color,'A2_mixed_color')\n",
    "\n",
    "print('A1 average content difference:', diffA1)\n",
    "print('A2 average content difference:', diffA2)\n",
    "\n",
    "print('A1 colored average Grammian difference:', np.mean((G_A2-G_A1asA2)**2))\n",
    "print('A2 colored average Grammian difference:', np.mean((G_A1-G_A2asA1)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAvFBYsXlssm"
   },
   "source": [
    "## New implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtyjBIeImmiu"
   },
   "source": [
    "Using the closed form solution of the transformation matrix is:\n",
    "\n",
    "$$T = \\Sigma_c^{-1/2}(\\Sigma_c^{1/2}\\Sigma_s\\Sigma_c^{1/2})^{1/2}\\Sigma_c^{-1/2}$$\n",
    "\n",
    "Useful link: https://stats.stackexchange.com/questions/363425/raising-a-variance-covariance-matrix-to-a-negative-half-power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1pnvsqLlcrO"
   },
   "outputs": [],
   "source": [
    "def matrix_to_power(matrix, power):\n",
    "    # Assuming real symmetric\n",
    "    e_val, e_vec = np.linalg.eigh(matrix)\n",
    "    lambda_ = np.diag(e_val**power)\n",
    "\n",
    "    return e_vec@lambda_@e_vec.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-r10Xptjzhit"
   },
   "outputs": [],
   "source": [
    "def new_transform(content_img, style_img):\n",
    "    sigma_c = np.cov(content_img)\n",
    "    sigma_s = np.cov(style_img)\n",
    "\n",
    "    simga_c_neg_half = matrix_to_power(sigma_c, -1/2)\n",
    "    sigma_c_half = matrix_to_power(sigma_c, 1/2)\n",
    "\n",
    "    inner = matrix_to_power(sigma_c_half@sigma_s@sigma_c_half, 1/2)\n",
    "\n",
    "    transform_mat = simga_c_neg_half@inner@simga_c_neg_half\n",
    "    return transform_mat@content_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = A1.reshape(channels, hw*hw)\n",
    "style = A2.reshape(channels, hw*hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored = new_transform(content, style)\n",
    "np.count_nonzero(np.isnan(colored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = show_gram(colored.reshape((channels,hw,hw)),'A1 with A2 style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Lab2-Style Transfer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
